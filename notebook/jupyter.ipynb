{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "FOKAxCy7yGlv",
        "rr_JaSW7zACc",
        "SjLHaI0s0QKC",
        "Ldw6w2Iz09Tq",
        "hEUhj74F1CEC"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup and Configuration"
      ],
      "metadata": {
        "id": "FoY6Fhdmw_ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from dateutil import parser\n",
        "import re\n",
        "from dataclasses import dataclass, field\n",
        "import time\n",
        "from typing import List, Tuple, Any, Set, Dict, Optional, Union, Callable\n",
        "import itertools\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from collections import Counter\n",
        "import json\n",
        "import pprint\n",
        "\n",
        "class Config:\n",
        "    BERT_MODEL_NAME: str = 'bert-base-uncased'\n",
        "    DEVICE: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    MAX_LENGTH: int = 128\n",
        "    MAX_REASONING_DEPTH: int = 5\n",
        "    INITIAL_RULE_CONFIDENCE: float = 0.9\n",
        "    PLAUSIBILITY_THRESHOLD: float = 0.5\n",
        "    ADAPTATION_LEARNING_RATE_NEURAL: float = 1e-5\n",
        "    ADAPTATION_LEARNING_RATE_SYMBOLIC: float = 0.1\n",
        "    RULE_GEN_MIN_SUPPORT: int = 2\n",
        "    RULE_GEN_CLUSTER_THRESHOLD: float = 0.8\n",
        "    DATA_DIR: str = \"data\"\n",
        "    SAMPLE_QA_FILENAME: str = \"sample_qa.json\"\n",
        "    DATA_PATH: str = os.path.join(DATA_DIR, SAMPLE_QA_FILENAME)\n",
        "\n",
        "config = Config()\n",
        "\n",
        "print(f\"Using device: {config.DEVICE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwXNOCQhxC1s",
        "outputId": "34a9963b-dfec-4fce-9905-2350b1fecb36"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility Functions"
      ],
      "metadata": {
        "id": "v4RvOVZ3xaxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeUtils:\n",
        "    @staticmethod\n",
        "    def parse_time(time_str: str) -> Optional[datetime]:\n",
        "        if not isinstance(time_str, str):\n",
        "             print(f\"Warning: parse_time expected string, got {type(time_str)}\")\n",
        "             return None\n",
        "        try:\n",
        "            return parser.parse(time_str)\n",
        "        except (ValueError, OverflowError, TypeError) as e:\n",
        "            print(f\"Warning: Could not parse time string: '{time_str}'. Error: {e}\")\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def parse_duration(duration_str: str) -> Optional[timedelta]:\n",
        "        if not isinstance(duration_str, str):\n",
        "             print(f\"Warning: parse_duration expected string, got {type(duration_str)}\")\n",
        "             return None\n",
        "\n",
        "        duration_str_lower = duration_str.lower()\n",
        "        minutes = 0\n",
        "        hours = 0\n",
        "\n",
        "        hour_match = re.search(r'(\\d+)\\s*(?:hr|hour|hours)', duration_str_lower)\n",
        "        min_match = re.search(r'(\\d+)\\s*(?:min|minute|minutes)', duration_str_lower)\n",
        "\n",
        "        if hour_match:\n",
        "            hours += int(hour_match.group(1))\n",
        "        if min_match:\n",
        "            minutes += int(min_match.group(1))\n",
        "\n",
        "        if hours == 0 and minutes == 0:\n",
        "            try:\n",
        "                num_match = re.search(r'^(\\d+)$', duration_str.strip())\n",
        "                if num_match:\n",
        "                     minutes += int(num_match.group(1))\n",
        "                     print(f\"Warning: Interpreting standalone number '{duration_str}' as minutes.\")\n",
        "            except (AttributeError, ValueError):\n",
        "                 pass\n",
        "\n",
        "        if minutes > 0 or hours > 0:\n",
        "            return timedelta(hours=hours, minutes=minutes)\n",
        "        else:\n",
        "            print(f\"Warning: Could not parse duration string: '{duration_str}'\")\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def format_time(dt_obj: datetime) -> str:\n",
        "        if not isinstance(dt_obj, datetime):\n",
        "            return \"Invalid Time\"\n",
        "        return dt_obj.strftime(\"%I:%M %p\")\n",
        "\n",
        "    @staticmethod\n",
        "    def format_timedelta(td_obj: timedelta) -> str:\n",
        "        if not isinstance(td_obj, timedelta):\n",
        "            return \"Invalid Duration\"\n",
        "\n",
        "        total_minutes = int(td_obj.total_seconds() / 60)\n",
        "        if total_minutes < 0:\n",
        "             sign = \"-\"\n",
        "             total_minutes = abs(total_minutes)\n",
        "        else:\n",
        "             sign = \"\"\n",
        "\n",
        "        hours = total_minutes // 60\n",
        "        minutes = total_minutes % 60\n",
        "        res = []\n",
        "        if hours > 0:\n",
        "            res.append(f\"{hours} hour{'s' if hours > 1 else ''}\")\n",
        "        if minutes > 0:\n",
        "            res.append(f\"{minutes} minute{'s' if minutes > 1 else ''}\")\n",
        "\n",
        "        if not res:\n",
        "            return \"0 minutes\"\n",
        "        else:\n",
        "            return sign + \" and \".join(res)\n",
        "\n",
        "print(\"--- Time Parsing ---\")\n",
        "t1 = TimeUtils.parse_time(\"3:00 PM\")\n",
        "t2 = TimeUtils.parse_time(\"14:15\")\n",
        "t3 = TimeUtils.parse_time(\"noon\")\n",
        "print(f\"'3:00 PM' -> {t1}\")\n",
        "print(f\"'14:15' -> {t2}\")\n",
        "print(f\"'noon' -> {t3}\")\n",
        "print(f\"'invalid time' -> {TimeUtils.parse_time('invalid time')}\")\n",
        "\n",
        "print(\"\\n--- Duration Parsing ---\")\n",
        "d1 = TimeUtils.parse_duration(\"30 minutes\")\n",
        "d2 = TimeUtils.parse_duration(\"1 hr and 15 min\")\n",
        "d3 = TimeUtils.parse_duration(\"45min\")\n",
        "d4 = TimeUtils.parse_duration(\"2 hours\")\n",
        "d5 = TimeUtils.parse_duration(\"invalid duration\")\n",
        "d6 = TimeUtils.parse_duration(\"120\")\n",
        "print(f\"'30 minutes' -> {d1}\")\n",
        "print(f\"'1 hr and 15 min' -> {d2}\")\n",
        "print(f\"'45min' -> {d3}\")\n",
        "print(f\"'2 hours' -> {d4}\")\n",
        "print(f\"'invalid duration' -> {d5}\")\n",
        "print(f\"'120' -> {d6}\")\n",
        "\n",
        "print(\"\\n--- Formatting ---\")\n",
        "if t1: print(f\"t1 formatted: {TimeUtils.format_time(t1)}\")\n",
        "if d2: print(f\"d2 formatted: {TimeUtils.format_timedelta(d2)}\")\n",
        "if t1 and d1:\n",
        "    departure = t1 - d1\n",
        "    print(f\"Meeting at {TimeUtils.format_time(t1)}, travel {TimeUtils.format_timedelta(d1)}, leave by {TimeUtils.format_time(departure)}\")\n",
        "\n",
        "print(f\"Formatting None: {TimeUtils.format_time(None)}, {TimeUtils.format_timedelta(None)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0-2XjwuxZlT",
        "outputId": "26d8df87-bbbe-426f-f5fe-1106993d5ca8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Time Parsing ---\n",
            "Warning: Could not parse time string: 'noon'. Error: Unknown string format: noon\n",
            "'3:00 PM' -> 2025-03-31 15:00:00\n",
            "'14:15' -> 2025-03-31 14:15:00\n",
            "'noon' -> None\n",
            "Warning: Could not parse time string: 'invalid time'. Error: Unknown string format: invalid time\n",
            "'invalid time' -> None\n",
            "\n",
            "--- Duration Parsing ---\n",
            "Warning: Could not parse duration string: 'invalid duration'\n",
            "Warning: Interpreting standalone number '120' as minutes.\n",
            "'30 minutes' -> 0:30:00\n",
            "'1 hr and 15 min' -> 1:15:00\n",
            "'45min' -> 0:45:00\n",
            "'2 hours' -> 2:00:00\n",
            "'invalid duration' -> None\n",
            "'120' -> 2:00:00\n",
            "\n",
            "--- Formatting ---\n",
            "t1 formatted: 03:00 PM\n",
            "d2 formatted: 1 hour and 15 minutes\n",
            "Meeting at 03:00 PM, travel 30 minutes, leave by 02:30 PM\n",
            "Formatting None: Invalid Time, Invalid Duration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Component"
      ],
      "metadata": {
        "id": "LuLoE41-xnnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertExtractor:\n",
        "    def __init__(self, model_name: str = config.BERT_MODEL_NAME, device: torch.device = config.DEVICE):\n",
        "        print(f\"Loading BERT model: {model_name}...\")\n",
        "        try:\n",
        "            self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "            self.model = BertModel.from_pretrained(model_name)\n",
        "            self.device = device\n",
        "            self.model.to(self.device)\n",
        "            self.model.eval()\n",
        "            print(\"BERT model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR: Failed to load BERT model '{model_name}'. Check model name and internet connection. Error: {e}\")\n",
        "            raise e\n",
        "\n",
        "    def get_embeddings(self, text: str) -> Optional[torch.Tensor]:\n",
        "        try:\n",
        "            inputs = self.tokenizer(\n",
        "                text,\n",
        "                return_tensors='pt',\n",
        "                max_length=config.MAX_LENGTH,\n",
        "                truncation=True,\n",
        "                padding='max_length'\n",
        "            )\n",
        "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "            cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "            return cls_embedding.cpu()\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating embedding for text: '{text}'. Error: {e}\")\n",
        "            return None\n",
        "\n",
        "    def extract_entities_relations(self, question: str) -> Dict[str, Any]:\n",
        "        entities = {'times': [], 'durations': []}\n",
        "        relations = []\n",
        "        event_id_counter = 1\n",
        "        event_name = f\"event{event_id_counter}\"\n",
        "\n",
        "        time_patterns = r'\\b(\\d{1,2}:\\d{2}\\s*(?:AM|PM)?|\\d{1,2}\\s*(?:AM|PM))\\b'\n",
        "        try:\n",
        "            found_times = re.findall(time_patterns, question, re.IGNORECASE)\n",
        "            for t_str in found_times:\n",
        "                parsed_time = TimeUtils.parse_time(t_str)\n",
        "                if parsed_time and not any(t['text'] == t_str for t in entities['times']):\n",
        "                    entities['times'].append({'text': t_str, 'value': parsed_time})\n",
        "        except Exception as e:\n",
        "            print(f\"Error during time regex extraction: {e}\")\n",
        "\n",
        "        duration_patterns = r'(\\d+\\s*(?:minute|minutes|min|hour|hours|hr)s?(?:\\s*(?:and|,)?\\s*\\d+\\s*(?:minute|minutes|min|hour|hours|hr)s?)?)'\n",
        "        simple_duration_patterns = r'(?:takes?|travel|drive|walk|lasts?|runs? for)\\s*(\\d+)\\b'\n",
        "        try:\n",
        "            found_durations = re.findall(duration_patterns, question, re.IGNORECASE)\n",
        "            found_simple_durations = re.findall(simple_duration_patterns, question, re.IGNORECASE)\n",
        "\n",
        "            all_duration_texts = found_durations + [f\"{m} minutes\" for m in found_simple_durations]\n",
        "\n",
        "            processed_duration_texts = set()\n",
        "            for d_str in all_duration_texts:\n",
        "                 d_str_cleaned = d_str.strip()\n",
        "                 if d_str_cleaned in processed_duration_texts: continue\n",
        "\n",
        "                 is_part_of_time = any(d_str_cleaned in t['text'] for t in entities['times'])\n",
        "                 if not is_part_of_time:\n",
        "                     parsed_duration = TimeUtils.parse_duration(d_str_cleaned)\n",
        "                     if parsed_duration:\n",
        "                         entities['durations'].append({'text': d_str_cleaned, 'value': parsed_duration})\n",
        "                         processed_duration_texts.add(d_str_cleaned)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during duration regex extraction: {e}\")\n",
        "\n",
        "        question_lower = question.lower()\n",
        "        if entities['times']:\n",
        "            first_time_val = entities['times'][0]['value']\n",
        "            if any(kw in question_lower for kw in [\"meeting\", \"appointment\", \"deadline\", \"flight is at\", \"event at\"]):\n",
        "                 relations.append(('event_time', event_name, first_time_val))\n",
        "            elif \"start\" in question_lower or \"begins\" in question_lower:\n",
        "                 relations.append(('start_time', event_name, first_time_val))\n",
        "            elif \"depart\" in question_lower or \"leaves at\" in question_lower:\n",
        "                 relations.append(('departure_time', event_name, first_time_val))\n",
        "\n",
        "        if entities['durations']:\n",
        "            first_duration_val = entities['durations'][0]['value']\n",
        "            if any(w in question_lower for w in [\"get there\", \"travel\", \"drive\", \"walk\", \"commute\", \"journey\"]):\n",
        "                 relations.append(('travel_time', event_name, first_duration_val))\n",
        "            elif any(kw in question_lower for kw in [\"runs for\", \"lasts\", \"duration of\", \"need\", \"takes\"]):\n",
        "                 if any(r[0] in ['start_time', 'event_time'] for r in relations):\n",
        "                      relations.append(('duration', event_name, first_duration_val))\n",
        "                 else:\n",
        "                      relations.append(('duration', event_name, first_duration_val))\n",
        "\n",
        "        query_variable = None\n",
        "        if \"when should i leave\" in question_lower or \"departure time\" in question_lower or \"latest departure\" in question_lower:\n",
        "            query_variable = ('departure_time', event_name, '?')\n",
        "        elif \"when does it end\" in question_lower or \"end time\" in question_lower or \"what time does it finish\" in question_lower or \"when will i arrive\" in question_lower:\n",
        "             if any(r[0] == 'travel_time' for r in relations) or any(kw in question_lower for kw in [\"arrive\", \"get there\"]):\n",
        "                  query_variable = ('arrival_time', event_name, '?')\n",
        "             else:\n",
        "                  query_variable = ('end_time', event_name, '?')\n",
        "        elif \"how long\" in question_lower or \"duration\" in question_lower:\n",
        "             query_variable = ('duration', event_name, '?')\n",
        "        elif \"when should i start\" in question_lower or \"start work\" in question_lower:\n",
        "             query_variable = ('start_work_time', event_name, '?')\n",
        "\n",
        "        embedding = self.get_embeddings(question)\n",
        "\n",
        "        return {\n",
        "            \"question\": question,\n",
        "            \"entities\": entities,\n",
        "            \"relations\": relations,\n",
        "            \"query\": query_variable,\n",
        "            \"embedding\": embedding\n",
        "        }\n",
        "\n",
        "    def fine_tune_step(self, batch_questions: List[str], batch_labels: List[Any], optimizer, criterion):\n",
        "        print(\"Warning: BertExtractor.fine_tune_step is a placeholder and not implemented.\")\n",
        "        pass\n",
        "\n",
        "\n",
        "extractor = BertExtractor(model_name=config.BERT_MODEL_NAME, device=config.DEVICE)\n",
        "\n",
        "questions = [\n",
        "    \"If I have a meeting at 3 PM and it takes 30 minutes to get there, when should I leave?\",\n",
        "    \"My train departs at 10:00 AM. The journey lasts 2 hours and 15 min. When will I arrive?\",\n",
        "    \"The workshop starts at 9 AM and runs for 3 hours. What time does it finish?\",\n",
        "    \"How long is a meeting from 2pm to 4:30pm?\"\n",
        "]\n",
        "\n",
        "for i, q in enumerate(questions):\n",
        "    print(f\"\\n--- Analyzing Question {i+1} ---\")\n",
        "    extracted_info = extractor.extract_entities_relations(q)\n",
        "    print(f\"Question: {extracted_info['question']}\")\n",
        "    print(\"Entities:\")\n",
        "    for entity_type, entity_list in extracted_info['entities'].items():\n",
        "        print(f\"  {entity_type}:\")\n",
        "        for entity in entity_list:\n",
        "            val_str = TimeUtils.format_time(entity['value']) if isinstance(entity['value'], datetime) else TimeUtils.format_timedelta(entity['value'])\n",
        "            print(f\"    - Text: '{entity['text']}', Value: {val_str}\")\n",
        "    print(\"Relations:\")\n",
        "    for rel in extracted_info['relations']:\n",
        "        obj_str = TimeUtils.format_time(rel[2]) if isinstance(rel[2], datetime) else TimeUtils.format_timedelta(rel[2])\n",
        "        print(f\"  - ({rel[0]}, {rel[1]}, {obj_str})\")\n",
        "    print(f\"Query: {extracted_info['query']}\")\n",
        "    if extracted_info['embedding'] is not None:\n",
        "        print(f\"Embedding Shape: {extracted_info['embedding'].shape}\")\n",
        "    else:\n",
        "        print(\"Embedding: Failed to generate.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiE82FUXxk66",
        "outputId": "19b9b3f6-6882-49a6-c7c7-cfc560ce0933"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT model: bert-base-uncased...\n",
            "BERT model loaded.\n",
            "\n",
            "--- Analyzing Question 1 ---\n",
            "Question: If I have a meeting at 3 PM and it takes 30 minutes to get there, when should I leave?\n",
            "Entities:\n",
            "  times:\n",
            "    - Text: '3 PM', Value: 03:00 PM\n",
            "  durations:\n",
            "    - Text: '30 minutes', Value: 30 minutes\n",
            "Relations:\n",
            "  - (event_time, event1, 03:00 PM)\n",
            "  - (travel_time, event1, 30 minutes)\n",
            "Query: ('departure_time', 'event1', '?')\n",
            "Embedding Shape: torch.Size([1, 768])\n",
            "\n",
            "--- Analyzing Question 2 ---\n",
            "Question: My train departs at 10:00 AM. The journey lasts 2 hours and 15 min. When will I arrive?\n",
            "Entities:\n",
            "  times:\n",
            "    - Text: '10:00 AM', Value: 10:00 AM\n",
            "  durations:\n",
            "    - Text: '2 hours and 15 min', Value: 2 hours and 15 minutes\n",
            "    - Text: '2 minutes', Value: 2 minutes\n",
            "Relations:\n",
            "  - (departure_time, event1, 10:00 AM)\n",
            "  - (travel_time, event1, 2 hours and 15 minutes)\n",
            "Query: ('arrival_time', 'event1', '?')\n",
            "Embedding Shape: torch.Size([1, 768])\n",
            "\n",
            "--- Analyzing Question 3 ---\n",
            "Question: The workshop starts at 9 AM and runs for 3 hours. What time does it finish?\n",
            "Entities:\n",
            "  times:\n",
            "    - Text: '9 AM', Value: 09:00 AM\n",
            "  durations:\n",
            "    - Text: '3 hours', Value: 3 hours\n",
            "    - Text: '3 minutes', Value: 3 minutes\n",
            "Relations:\n",
            "  - (start_time, event1, 09:00 AM)\n",
            "  - (duration, event1, 3 hours)\n",
            "Query: ('end_time', 'event1', '?')\n",
            "Embedding Shape: torch.Size([1, 768])\n",
            "\n",
            "--- Analyzing Question 4 ---\n",
            "Question: How long is a meeting from 2pm to 4:30pm?\n",
            "Entities:\n",
            "  times:\n",
            "    - Text: '2pm', Value: 02:00 PM\n",
            "    - Text: '4:30pm', Value: 04:30 PM\n",
            "  durations:\n",
            "Relations:\n",
            "  - (event_time, event1, 02:00 PM)\n",
            "Query: ('duration', 'event1', '?')\n",
            "Embedding Shape: torch.Size([1, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbolic Component"
      ],
      "metadata": {
        "id": "nSM44Bvsxs_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass(frozen=True, eq=True)\n",
        "class Fact:\n",
        "    predicate: str\n",
        "    subject: str\n",
        "    object: Any\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        obj_str = self.object\n",
        "        if isinstance(self.object, datetime):\n",
        "            obj_str = TimeUtils.format_time(self.object)\n",
        "        elif isinstance(self.object, timedelta):\n",
        "            obj_str = TimeUtils.format_timedelta(self.object)\n",
        "        elif isinstance(self.object, str) and self.object == '?':\n",
        "             obj_str = '?'\n",
        "        return f\"{self.predicate}({self.subject}, {obj_str})\"\n",
        "\n",
        "@dataclass\n",
        "class Rule:\n",
        "    conditions: List[Tuple[str, str, str]]\n",
        "    conclusion: Tuple[str, str, str]\n",
        "    confidence: float = field(default=config.INITIAL_RULE_CONFIDENCE)\n",
        "    source: str = field(default=\"manual\")\n",
        "    id: int = field(default_factory=itertools.count().__next__, init=False)\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        cond_str = \" AND \".join([f\"{p}({s}, {o})\" for p, s, o in self.conditions])\n",
        "        conc_str = f\"{self.conclusion[0]}({self.conclusion[1]}, {self.conclusion[2]})\"\n",
        "        return f\"Rule {self.id} ({self.confidence:.2f}, {self.source}): IF {cond_str} THEN {conc_str}\"\n",
        "\n",
        "class SymbolicReasoner:\n",
        "    def __init__(self):\n",
        "        self.facts: Set[Fact] = set()\n",
        "        self.rules: List[Rule] = []\n",
        "        self._add_core_temporal_rules()\n",
        "\n",
        "    def _add_core_temporal_rules(self):\n",
        "        core_rules_data = [\n",
        "            {\n",
        "                \"conditions\": [('event_time', '?e', '?t'), ('travel_time', '?e', '?d')],\n",
        "                \"conclusion\": ('departure_time', '?e', 'calculate_departure(?t, ?d)'),\n",
        "            },\n",
        "            {\n",
        "                \"conditions\": [('start_time', '?e', '?t'), ('duration', '?e', '?d')],\n",
        "                \"conclusion\": ('end_time', '?e', 'calculate_end(?t, ?d)'),\n",
        "            },\n",
        "             {\n",
        "                \"conditions\": [('event_time', '?e', '?t'), ('duration', '?e', '?d')],\n",
        "                \"conclusion\": ('end_time', '?e', 'calculate_end(?t, ?d)'),\n",
        "            },\n",
        "            {\n",
        "                \"conditions\": [('start_time', '?e', '?t1'), ('end_time', '?e', '?t2')],\n",
        "                \"conclusion\": ('duration', '?e', 'calculate_duration(?t1, ?t2)'),\n",
        "            },\n",
        "             {\n",
        "                \"conditions\": [('event_time', '?e', '?t'), ('duration', '?e', '?d')],\n",
        "                \"conclusion\": ('start_work_time', '?e', 'calculate_departure(?t, ?d)'),\n",
        "            },\n",
        "             {\n",
        "                \"conditions\": [('departure_time', '?e', '?t'), ('travel_time', '?e', '?d')],\n",
        "                \"conclusion\": ('arrival_time', '?e', 'calculate_end(?t, ?d)'),\n",
        "            },\n",
        "        ]\n",
        "        for rule_data in core_rules_data:\n",
        "             self.add_rule(\n",
        "                 conditions=rule_data[\"conditions\"],\n",
        "                 conclusion=rule_data[\"conclusion\"],\n",
        "                 source=\"core_temporal\",\n",
        "                 confidence=1.0\n",
        "             )\n",
        "        print(f\"Added {len(self.rules)} core temporal rules.\")\n",
        "\n",
        "\n",
        "    def add_fact(self, fact: Fact) -> bool:\n",
        "        if not isinstance(fact, Fact):\n",
        "             print(f\"Warning: Attempted to add non-Fact object: {fact}\")\n",
        "             return False\n",
        "        if fact not in self.facts:\n",
        "            self.facts.add(fact)\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def add_rule(self, conditions: List[Tuple[str, str, str]],\n",
        "                 conclusion: Tuple[str, str, str],\n",
        "                 confidence: float = config.INITIAL_RULE_CONFIDENCE,\n",
        "                 source: str = \"manual\") -> Rule:\n",
        "        rule = Rule(conditions=conditions, conclusion=conclusion, confidence=confidence, source=source)\n",
        "        self.rules.append(rule)\n",
        "        return rule\n",
        "\n",
        "    def reason(self, max_depth: int = config.MAX_REASONING_DEPTH) -> Tuple[Set[Fact], List[Tuple[Rule, Dict[str, Any], Fact]]]:\n",
        "        all_newly_derived_facts_overall = set()\n",
        "        reasoning_trace = []\n",
        "        current_facts = self.facts.copy()\n",
        "        depth = 0\n",
        "\n",
        "        while depth < max_depth:\n",
        "            made_change_this_iteration = False\n",
        "            newly_derived_this_iteration = set()\n",
        "\n",
        "            active_rules = [r for r in self.rules if r.confidence > 0.1]\n",
        "\n",
        "            for rule in active_rules:\n",
        "                bindings_list = self._find_bindings(rule.conditions, current_facts)\n",
        "\n",
        "                for bindings in bindings_list:\n",
        "                    derived_fact = self._derive_conclusion(rule.conclusion, bindings)\n",
        "\n",
        "                    if derived_fact and derived_fact not in current_facts and derived_fact not in newly_derived_this_iteration:\n",
        "                        newly_derived_this_iteration.add(derived_fact)\n",
        "                        reasoning_trace.append((rule, bindings, derived_fact))\n",
        "                        made_change_this_iteration = True\n",
        "\n",
        "            if not made_change_this_iteration:\n",
        "                break\n",
        "\n",
        "            current_facts.update(newly_derived_this_iteration)\n",
        "            all_newly_derived_facts_overall.update(newly_derived_this_iteration)\n",
        "            depth += 1\n",
        "\n",
        "        if depth == max_depth:\n",
        "             print(f\"Warning: Reasoning reached maximum depth ({max_depth}).\")\n",
        "\n",
        "        self.facts = current_facts\n",
        "        return all_newly_derived_facts_overall, reasoning_trace\n",
        "\n",
        "    def _find_bindings(self, conditions: List[Tuple[str, str, str]], current_facts: Set[Fact]) -> List[Dict[str, Any]]:\n",
        "        possible_bindings_list = []\n",
        "        current_bindings_list = [{}]\n",
        "\n",
        "        for predicate, subj_var, obj_var in conditions:\n",
        "            next_bindings_list = []\n",
        "            is_subj_variable = subj_var.startswith('?')\n",
        "            is_obj_variable = obj_var.startswith('?')\n",
        "\n",
        "            for existing_binding in current_bindings_list:\n",
        "                for fact in current_facts:\n",
        "                    if fact.predicate == predicate:\n",
        "                        new_binding = existing_binding.copy()\n",
        "                        consistent = True\n",
        "\n",
        "                        if is_subj_variable:\n",
        "                            if subj_var in new_binding:\n",
        "                                if new_binding[subj_var] != fact.subject:\n",
        "                                    consistent = False\n",
        "                            else:\n",
        "                                new_binding[subj_var] = fact.subject\n",
        "                        elif subj_var != fact.subject:\n",
        "                            consistent = False\n",
        "\n",
        "                        if consistent:\n",
        "                            if is_obj_variable:\n",
        "                                if obj_var in new_binding:\n",
        "                                    if type(new_binding[obj_var]) != type(fact.object) or new_binding[obj_var] != fact.object:\n",
        "                                        consistent = False\n",
        "                                else:\n",
        "                                    new_binding[obj_var] = fact.object\n",
        "                            elif type(obj_var) != type(fact.object) or obj_var != fact.object:\n",
        "                                consistent = False\n",
        "\n",
        "                        if consistent:\n",
        "                            next_bindings_list.append(new_binding)\n",
        "\n",
        "            current_bindings_list = next_bindings_list\n",
        "            if not current_bindings_list:\n",
        "                return []\n",
        "\n",
        "        unique_bindings_tuples = {tuple(sorted(b.items())) for b in current_bindings_list}\n",
        "        final_bindings_list = [dict(t) for t in unique_bindings_tuples]\n",
        "\n",
        "        return final_bindings_list\n",
        "\n",
        "\n",
        "    def _derive_conclusion(self, conclusion_pattern: Tuple[str, str, str], bindings: Dict[str, Any]) -> Optional[Fact]:\n",
        "        conc_pred, conc_subj_var, conc_obj_expr = conclusion_pattern\n",
        "\n",
        "        try:\n",
        "            subj = bindings.get(conc_subj_var)\n",
        "            if subj is None:\n",
        "                 if not conc_subj_var.startswith('?'):\n",
        "                      subj = conc_subj_var\n",
        "                 else:\n",
        "                      return None\n",
        "\n",
        "            obj = None\n",
        "            if isinstance(conc_obj_expr, str) and conc_obj_expr.startswith('calculate_'):\n",
        "                match = re.match(r'calculate_(\\w+)\\((.+)\\)', conc_obj_expr)\n",
        "                if not match:\n",
        "                     print(f\"Warning: Invalid calculation format: {conc_obj_expr}\")\n",
        "                     return None\n",
        "                func_name = \"calculate_\" + match.group(1)\n",
        "                arg_vars = [v.strip() for v in match.group(2).split(',')]\n",
        "\n",
        "                args = []\n",
        "                for var in arg_vars:\n",
        "                    if var not in bindings:\n",
        "                        return None\n",
        "                    args.append(bindings[var])\n",
        "\n",
        "                if func_name == 'calculate_departure' and len(args) == 2 and isinstance(args[0], datetime) and isinstance(args[1], timedelta):\n",
        "                    obj = args[0] - args[1]\n",
        "                elif func_name == 'calculate_end' and len(args) == 2 and isinstance(args[0], datetime) and isinstance(args[1], timedelta):\n",
        "                    obj = args[0] + args[1]\n",
        "                elif func_name == 'calculate_duration' and len(args) == 2 and isinstance(args[0], datetime) and isinstance(args[1], datetime):\n",
        "                    obj = args[1] - args[0]\n",
        "                    if obj < timedelta(0):\n",
        "                         print(f\"Warning: Calculated negative duration for {conc_pred} with args {args}. Start time might be after end time.\")\n",
        "                else:\n",
        "                    print(f\"Warning: Unknown calculation function '{func_name}' or incorrect argument types/count for args: {args}\")\n",
        "                    return None\n",
        "            else:\n",
        "                obj = bindings.get(conc_obj_expr)\n",
        "                if obj is None:\n",
        "                    if not isinstance(conc_obj_expr, str) or not conc_obj_expr.startswith('?'):\n",
        "                         obj = conc_obj_expr\n",
        "                    else:\n",
        "                         return None\n",
        "\n",
        "            if isinstance(subj, str) and subj.startswith('?'): return None\n",
        "            if isinstance(obj, str) and obj.startswith('?'): return None\n",
        "\n",
        "            if obj is None:\n",
        "                 return None\n",
        "\n",
        "            return Fact(predicate=conc_pred, subject=str(subj), object=obj)\n",
        "\n",
        "        except KeyError as e:\n",
        "            print(f\"Error: KeyError during conclusion derivation for {conclusion_pattern}. Missing binding for {e}. Bindings: {bindings}\")\n",
        "            return None\n",
        "        except TypeError as e:\n",
        "            print(f\"Error: TypeError during calculation for {conclusion_pattern}. Bindings: {bindings}. Error: {e}\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"Error: Unexpected error during conclusion derivation for {conclusion_pattern}. Bindings: {bindings}. Error: {e}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "    def query(self, query_pattern: Tuple[str, str, str]) -> List[Fact]:\n",
        "        if not isinstance(query_pattern, tuple) or len(query_pattern) != 3:\n",
        "             print(f\"Error: Invalid query pattern format: {query_pattern}\")\n",
        "             return []\n",
        "\n",
        "        q_pred, q_subj, q_obj = query_pattern\n",
        "        results = []\n",
        "        for fact in self.facts:\n",
        "            match = True\n",
        "            if fact.predicate != q_pred:\n",
        "                match = False\n",
        "            if q_subj != '?' and fact.subject != q_subj:\n",
        "                match = False\n",
        "            if q_obj != '?':\n",
        "                if type(fact.object) != type(q_obj) or fact.object != q_obj:\n",
        "                    match = False\n",
        "\n",
        "\n",
        "            if match:\n",
        "                results.append(fact)\n",
        "        return results\n",
        "\n",
        "    def get_all_facts(self) -> Set[Fact]:\n",
        "        return self.facts\n",
        "\n",
        "    def get_all_rules(self) -> List[Rule]:\n",
        "        return self.rules\n",
        "\n",
        "    def clear_facts(self):\n",
        "        self.facts.clear()\n",
        "\n",
        "    def clear_rules(self):\n",
        "        self.rules.clear()\n",
        "\n",
        "\n",
        "reasoner = SymbolicReasoner()\n",
        "\n",
        "print(\"--- Example 1: Departure Time ---\")\n",
        "reasoner.clear_facts()\n",
        "t1 = TimeUtils.parse_time(\"3 PM\")\n",
        "d1 = TimeUtils.parse_duration(\"30 minutes\")\n",
        "if t1: reasoner.add_fact(Fact('event_time', 'event1', t1))\n",
        "if d1: reasoner.add_fact(Fact('travel_time', 'event1', d1))\n",
        "\n",
        "print(\"Initial Facts:\")\n",
        "for f in reasoner.get_all_facts(): print(f\"  {f}\")\n",
        "print(\"\\nApplying Rules...\")\n",
        "new_facts, trace = reasoner.reason()\n",
        "\n",
        "print(\"\\nNew Facts Derived:\")\n",
        "for f in new_facts: print(f\"  {f}\")\n",
        "\n",
        "print(\"\\nQuerying for departure_time(event1, ?):\")\n",
        "results = reasoner.query(('departure_time', 'event1', '?'))\n",
        "if results:\n",
        "    print(f\"  Found Answer: {results[0]}\")\n",
        "else:\n",
        "    print(\"  Answer not found.\")\n",
        "\n",
        "print(\"\\n--- Example 2: End Time ---\")\n",
        "reasoner.clear_facts()\n",
        "t2 = TimeUtils.parse_time(\"9:00 AM\")\n",
        "d2 = TimeUtils.parse_duration(\"3 hours\")\n",
        "if t2: reasoner.add_fact(Fact('start_time', 'event2', t2))\n",
        "if d2: reasoner.add_fact(Fact('duration', 'event2', d2))\n",
        "\n",
        "print(\"Initial Facts:\")\n",
        "for f in reasoner.get_all_facts(): print(f\"  {f}\")\n",
        "print(\"\\nApplying Rules...\")\n",
        "new_facts, trace = reasoner.reason()\n",
        "\n",
        "print(\"\\nNew Facts Derived:\")\n",
        "for f in new_facts: print(f\"  {f}\")\n",
        "\n",
        "print(\"\\nQuerying for end_time(event2, ?):\")\n",
        "results = reasoner.query(('end_time', 'event2', '?'))\n",
        "if results:\n",
        "    print(f\"  Found Answer: {results[0]}\")\n",
        "else:\n",
        "    print(\"  Answer not found.\")\n",
        "\n",
        "print(\"\\n--- Example 3: Duration ---\")\n",
        "reasoner.clear_facts()\n",
        "t3_start = TimeUtils.parse_time(\"2 PM\")\n",
        "t3_end = TimeUtils.parse_time(\"4:30 PM\")\n",
        "if t3_start: reasoner.add_fact(Fact('start_time', 'event3', t3_start))\n",
        "if t3_end: reasoner.add_fact(Fact('end_time', 'event3', t3_end))\n",
        "\n",
        "print(\"Initial Facts:\")\n",
        "for f in reasoner.get_all_facts(): print(f\"  {f}\")\n",
        "print(\"\\nApplying Rules...\")\n",
        "new_facts, trace = reasoner.reason()\n",
        "\n",
        "print(\"\\nNew Facts Derived:\")\n",
        "for f in new_facts: print(f\"  {f}\")\n",
        "\n",
        "print(\"\\nQuerying for duration(event3, ?):\")\n",
        "results = reasoner.query(('duration', 'event3', '?'))\n",
        "if results:\n",
        "    print(f\"  Found Answer: {results[0]}\")\n",
        "else:\n",
        "    print(\"  Answer not found.\")\n",
        "\n",
        "print(\"\\n--- All Rules in Reasoner ---\")\n",
        "for r in reasoner.get_all_rules(): print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHpUSFBqxvMe",
        "outputId": "7a12f529-c7f0-44a9-f126-88e223f33962"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 6 core temporal rules.\n",
            "--- Example 1: Departure Time ---\n",
            "Initial Facts:\n",
            "  event_time(event1, 03:00 PM)\n",
            "  travel_time(event1, 30 minutes)\n",
            "\n",
            "Applying Rules...\n",
            "\n",
            "New Facts Derived:\n",
            "  arrival_time(event1, 03:00 PM)\n",
            "  departure_time(event1, 02:30 PM)\n",
            "\n",
            "Querying for departure_time(event1, ?):\n",
            "  Found Answer: departure_time(event1, 02:30 PM)\n",
            "\n",
            "--- Example 2: End Time ---\n",
            "Initial Facts:\n",
            "  duration(event2, 3 hours)\n",
            "  start_time(event2, 09:00 AM)\n",
            "\n",
            "Applying Rules...\n",
            "\n",
            "New Facts Derived:\n",
            "  end_time(event2, 12:00 PM)\n",
            "\n",
            "Querying for end_time(event2, ?):\n",
            "  Found Answer: end_time(event2, 12:00 PM)\n",
            "\n",
            "--- Example 3: Duration ---\n",
            "Initial Facts:\n",
            "  start_time(event3, 02:00 PM)\n",
            "  end_time(event3, 04:30 PM)\n",
            "\n",
            "Applying Rules...\n",
            "\n",
            "New Facts Derived:\n",
            "  duration(event3, 2 hours and 30 minutes)\n",
            "\n",
            "Querying for duration(event3, ?):\n",
            "  Found Answer: duration(event3, 2 hours and 30 minutes)\n",
            "\n",
            "--- All Rules in Reasoner ---\n",
            "Rule 0 (1.00, core_temporal): IF event_time(?e, ?t) AND travel_time(?e, ?d) THEN departure_time(?e, calculate_departure(?t, ?d))\n",
            "Rule 1 (1.00, core_temporal): IF start_time(?e, ?t) AND duration(?e, ?d) THEN end_time(?e, calculate_end(?t, ?d))\n",
            "Rule 2 (1.00, core_temporal): IF event_time(?e, ?t) AND duration(?e, ?d) THEN end_time(?e, calculate_end(?t, ?d))\n",
            "Rule 3 (1.00, core_temporal): IF start_time(?e, ?t1) AND end_time(?e, ?t2) THEN duration(?e, calculate_duration(?t1, ?t2))\n",
            "Rule 4 (1.00, core_temporal): IF event_time(?e, ?t) AND duration(?e, ?d) THEN start_work_time(?e, calculate_departure(?t, ?d))\n",
            "Rule 5 (1.00, core_temporal): IF departure_time(?e, ?t) AND travel_time(?e, ?d) THEN arrival_time(?e, calculate_end(?t, ?d))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integration Layer"
      ],
      "metadata": {
        "id": "FOKAxCy7yGlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralToSymbolicTranslator:\n",
        "    def translate(self, neural_output: Dict[str, Any], reasoner: SymbolicReasoner) -> int:\n",
        "        added_facts_count = 0\n",
        "        if not isinstance(neural_output, dict) or 'relations' not in neural_output:\n",
        "             print(\"Error: Invalid neural_output format for translation. Expected dict with 'relations'.\")\n",
        "             return -1\n",
        "        if not isinstance(reasoner, SymbolicReasoner):\n",
        "             print(\"Error: Invalid reasoner object provided for translation.\")\n",
        "             return -1\n",
        "\n",
        "        relations = neural_output.get('relations', [])\n",
        "        if not isinstance(relations, list):\n",
        "             print(\"Warning: 'relations' in neural_output is not a list.\")\n",
        "             relations = []\n",
        "\n",
        "        for relation in relations:\n",
        "            if isinstance(relation, tuple) and len(relation) == 3:\n",
        "                predicate, subject, obj = relation\n",
        "                if isinstance(predicate, str) and isinstance(subject, str):\n",
        "                    try:\n",
        "                        fact = Fact(predicate=predicate, subject=subject, object=obj)\n",
        "                        if reasoner.add_fact(fact):\n",
        "                            added_facts_count += 1\n",
        "                    except Exception as e:\n",
        "                         print(f\"Error creating Fact from relation {relation}: {e}\")\n",
        "                else:\n",
        "                    print(f\"Warning: Skipping invalid relation format: {relation}\")\n",
        "            else:\n",
        "                 print(f\"Warning: Skipping invalid relation format: {relation}\")\n",
        "\n",
        "\n",
        "        return added_facts_count\n",
        "\n",
        "extractor = BertExtractor()\n",
        "reasoner = SymbolicReasoner()\n",
        "translator = NeuralToSymbolicTranslator()\n",
        "\n",
        "q1 = \"If I have a meeting at 3 PM and it takes 30 minutes to get there, when should I leave?\"\n",
        "neural_out1 = extractor.extract_entities_relations(q1)\n",
        "\n",
        "print(\"--- Neural Output ---\")\n",
        "\n",
        "print(f\"Relations: {neural_out1.get('relations')}\")\n",
        "print(f\"Query: {neural_out1.get('query')}\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Translating to Symbolic Facts ---\")\n",
        "num_added = translator.translate(neural_out1, reasoner)\n",
        "print(f\"Added {num_added} facts.\")\n",
        "\n",
        "print(\"\\n--- Facts in Reasoner (Before Reasoning) ---\")\n",
        "if not reasoner.get_all_facts():\n",
        "    print(\"  No facts in reasoner.\")\n",
        "else:\n",
        "    for f in reasoner.get_all_facts(): print(f\"  {f}\")\n",
        "\n",
        "print(\"\\n--- Performing Symbolic Reasoning ---\")\n",
        "new_facts, trace = reasoner.reason()\n",
        "print(f\"Derived {len(new_facts)} new facts.\")\n",
        "\n",
        "print(\"\\n--- Querying for Result ---\")\n",
        "query_pattern = neural_out1.get('query')\n",
        "if query_pattern:\n",
        "    results = reasoner.query(query_pattern)\n",
        "    if results:\n",
        "        print(f\"Answer Found for {query_pattern}: {results[0]}\")\n",
        "    else:\n",
        "        print(f\"Answer not found for query: {query_pattern}\")\n",
        "else:\n",
        "    print(\"No query identified in neural output.\")\n",
        "\n",
        "print(\"\\n--- All Facts After Reasoning ---\")\n",
        "if not reasoner.get_all_facts():\n",
        "    print(\"  No facts in reasoner.\")\n",
        "else:\n",
        "    for f in reasoner.get_all_facts(): print(f\"  {f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR1LPgEiyE7L",
        "outputId": "1b8aa6c6-c6b8-494f-e90c-611dd2f4cbcc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT model: bert-base-uncased...\n",
            "BERT model loaded.\n",
            "Added 6 core temporal rules.\n",
            "--- Neural Output ---\n",
            "Relations: [('event_time', 'event1', datetime.datetime(2025, 3, 31, 15, 0)), ('travel_time', 'event1', datetime.timedelta(seconds=1800))]\n",
            "Query: ('departure_time', 'event1', '?')\n",
            "\n",
            "--- Translating to Symbolic Facts ---\n",
            "Added 2 facts.\n",
            "\n",
            "--- Facts in Reasoner (Before Reasoning) ---\n",
            "  event_time(event1, 03:00 PM)\n",
            "  travel_time(event1, 30 minutes)\n",
            "\n",
            "--- Performing Symbolic Reasoning ---\n",
            "Derived 2 new facts.\n",
            "\n",
            "--- Querying for Result ---\n",
            "Answer Found for ('departure_time', 'event1', '?'): departure_time(event1, 02:30 PM)\n",
            "\n",
            "--- All Facts After Reasoning ---\n",
            "  arrival_time(event1, 03:00 PM)\n",
            "  departure_time(event1, 02:30 PM)\n",
            "  event_time(event1, 03:00 PM)\n",
            "  travel_time(event1, 30 minutes)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Meta-Cognitive Component"
      ],
      "metadata": {
        "id": "rr_JaSW7zACc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MetaCognitiveEvaluator:\n",
        "    def evaluate_plausibility(self,\n",
        "                              answer_fact: Fact,\n",
        "                              context_facts: Set[Fact]\n",
        "                             ) -> Tuple[bool, str, float]:\n",
        "        if not isinstance(answer_fact, Fact):\n",
        "             return False, \"Invalid answer fact provided for evaluation.\", 0.0\n",
        "        if not isinstance(context_facts, set):\n",
        "             context_facts = set() if context_facts is None else set(context_facts)\n",
        "\n",
        "        predicate = answer_fact.predicate\n",
        "        subject = answer_fact.subject\n",
        "        value = answer_fact.object\n",
        "\n",
        "        if predicate == 'departure_time' and isinstance(value, datetime):\n",
        "            event_time_fact = next((f for f in context_facts if f.predicate == 'event_time' and f.subject == subject and isinstance(f.object, datetime)), None)\n",
        "            if event_time_fact:\n",
        "                if value >= event_time_fact.object:\n",
        "                    explanation = (f\"Evaluation Failed: Departure time ({TimeUtils.format_time(value)}) \"\n",
        "                                   f\"is not before the event time ({TimeUtils.format_time(event_time_fact.object)}).\")\n",
        "                    return False, explanation, 0.0\n",
        "\n",
        "        elif predicate == 'end_time' and isinstance(value, datetime):\n",
        "            start_time_fact = next((f for f in context_facts if f.predicate == 'start_time' and f.subject == subject and isinstance(f.object, datetime)), None)\n",
        "            if start_time_fact:\n",
        "                if value <= start_time_fact.object:\n",
        "                    explanation = (f\"Evaluation Failed: End time ({TimeUtils.format_time(value)}) \"\n",
        "                                   f\"is not after the start time ({TimeUtils.format_time(start_time_fact.object)}).\")\n",
        "                    return False, explanation, 0.0\n",
        "\n",
        "                duration_fact = next((f for f in context_facts if f.predicate == 'duration' and f.subject == subject and isinstance(f.object, timedelta)), None)\n",
        "                if duration_fact:\n",
        "                    expected_end_time = start_time_fact.object + duration_fact.object\n",
        "\n",
        "                    if abs((value - expected_end_time).total_seconds()) > 60:\n",
        "                        explanation = (f\"Evaluation Warning: Calculated end time ({TimeUtils.format_time(value)}) \"\n",
        "                                       f\"differs significantly from start time + duration \"\n",
        "                                       f\"({TimeUtils.format_time(expected_end_time)}).\")\n",
        "\n",
        "                        return True, explanation, 0.7\n",
        "\n",
        "        elif predicate == 'arrival_time' and isinstance(value, datetime):\n",
        "             departure_time_fact = next((f for f in context_facts if f.predicate == 'departure_time' and f.subject == subject and isinstance(f.object, datetime)), None)\n",
        "             if departure_time_fact:\n",
        "                  if value <= departure_time_fact.object:\n",
        "                       explanation = (f\"Evaluation Failed: Arrival time ({TimeUtils.format_time(value)}) \"\n",
        "                                      f\"is not after the departure time ({TimeUtils.format_time(departure_time_fact.object)}).\")\n",
        "                       return False, explanation, 0.0\n",
        "\n",
        "                  travel_time_fact = next((f for f in context_facts if f.predicate == 'travel_time' and f.subject == subject and isinstance(f.object, timedelta)), None)\n",
        "                  if travel_time_fact:\n",
        "                      expected_arrival_time = departure_time_fact.object + travel_time_fact.object\n",
        "                      if abs((value - expected_arrival_time).total_seconds()) > 60:\n",
        "                           explanation = (f\"Evaluation Warning: Calculated arrival time ({TimeUtils.format_time(value)}) \"\n",
        "                                          f\"differs significantly from departure time + travel time \"\n",
        "                                          f\"({TimeUtils.format_time(expected_arrival_time)}).\")\n",
        "                           return True, explanation, 0.7\n",
        "\n",
        "        elif predicate == 'duration' and isinstance(value, timedelta):\n",
        "            if value.total_seconds() < 0:\n",
        "                explanation = f\"Evaluation Failed: Duration ({TimeUtils.format_timedelta(value)}) cannot be negative.\"\n",
        "                return False, explanation, 0.0\n",
        "\n",
        "        explanation = \"Evaluation Passed: Answer appears plausible based on implemented checks.\"\n",
        "        return True, explanation, 1.0\n",
        "\n",
        "    def generate_explanation(self,\n",
        "                             query: Optional[Tuple[str, str, str]],\n",
        "                             answer_fact: Optional[Fact],\n",
        "                             reasoning_trace: List[Tuple[Rule, Dict[str, Any], Fact]],\n",
        "                             plausibility_result: Optional[Tuple[bool, str, float]]\n",
        "                            ) -> str:\n",
        "        explanation_lines = []\n",
        "        query_str = f\"{query[0]}({query[1]}, {query[2]})\" if query else \"No query specified\"\n",
        "        explanation_lines.append(f\"Query: {query_str}\")\n",
        "\n",
        "        explanation_lines.append(\"\\nReasoning Steps:\")\n",
        "        if not reasoning_trace:\n",
        "            if answer_fact:\n",
        "                 explanation_lines.append(f\" - Answer '{answer_fact}' was likely provided as an initial fact (no rules applied).\")\n",
        "            else:\n",
        "                 explanation_lines.append(\" - No rules could be applied, or no relevant facts were available.\")\n",
        "        else:\n",
        "            relevant_trace = []\n",
        "            processed_rules = set()\n",
        "            if answer_fact:\n",
        "                 final_steps = [step for step in reasoning_trace if step[2] == answer_fact]\n",
        "                 if final_steps:\n",
        "                      for step in final_steps:\n",
        "                           rule_id = step[0].id\n",
        "                           if (rule_id, step[2]) not in processed_rules:\n",
        "                                relevant_trace.append(step)\n",
        "                                processed_rules.add((rule_id, step[2]))\n",
        "                 else:\n",
        "                      explanation_lines.append(f\" - Trace does not directly show derivation of answer {answer_fact}. Showing all steps:\")\n",
        "                      relevant_trace = reasoning_trace\n",
        "            else:\n",
        "                 relevant_trace = reasoning_trace\n",
        "            if not relevant_trace and reasoning_trace:\n",
        "                 relevant_trace = reasoning_trace\n",
        "            relevant_trace.sort(key=lambda step: (step[0].id, str(step[2])))\n",
        "            for rule, bindings, derived_fact in relevant_trace:\n",
        "                 if (rule.id, derived_fact) in processed_rules and len(relevant_trace) > 1: continue\n",
        "                 processed_rules.add((rule.id, derived_fact))\n",
        "                 bound_vars_str = {}\n",
        "                 for k, v in bindings.items():\n",
        "                      if isinstance(v, datetime): bound_vars_str[k] = TimeUtils.format_time(v)\n",
        "                      elif isinstance(v, timedelta): bound_vars_str[k] = TimeUtils.format_timedelta(v)\n",
        "                      else: bound_vars_str[k] = str(v)\n",
        "                 explanation_lines.append(f\" - Applied Rule {rule.id} ({rule.source}, conf: {rule.confidence:.2f}):\")\n",
        "                 explanation_lines.append(f\"     IF {' AND '.join([f'{p}({s}, {o})' for p, s, o in rule.conditions])}\")\n",
        "                 explanation_lines.append(f\"     THEN {rule.conclusion[0]}({rule.conclusion[1]}, {rule.conclusion[2]})\")\n",
        "                 explanation_lines.append(f\"     With Bindings: {bound_vars_str}\")\n",
        "                 explanation_lines.append(f\"     Derived Fact: {derived_fact}\")\n",
        "\n",
        "        explanation_lines.append(f\"\\nFinal Answer: {answer_fact if answer_fact else 'Not Found'}\")\n",
        "\n",
        "        explanation_lines.append(\"\\nPlausibility Check:\")\n",
        "        if plausibility_result:\n",
        "            is_plausible, plaus_explanation, plaus_confidence = plausibility_result\n",
        "            status = 'Passed' if is_plausible else ('Warning' if plaus_confidence > config.PLAUSIBILITY_THRESHOLD and plaus_confidence < 1.0 else 'Failed')\n",
        "            explanation_lines.append(f\" - Status: {status} (Confidence: {plaus_confidence:.2f})\")\n",
        "            explanation_lines.append(f\" - Details: {plaus_explanation}\")\n",
        "        elif answer_fact:\n",
        "             explanation_lines.append(\" - Not performed (or failed).\")\n",
        "        else:\n",
        "            explanation_lines.append(\" - Not applicable (no answer found).\")\n",
        "\n",
        "        return \"\\n\".join(explanation_lines)\n",
        "\n",
        "class AdaptiveLearner:\n",
        "    def __init__(self,\n",
        "                 neural_model: 'BertExtractor',\n",
        "                 symbolic_reasoner: 'SymbolicReasoner',\n",
        "                 rule_generator: 'DynamicRuleGenerator'):\n",
        "        self.neural_model = neural_model\n",
        "        self.symbolic_reasoner = symbolic_reasoner\n",
        "        self.rule_generator = rule_generator\n",
        "\n",
        "    def update_on_feedback(self,\n",
        "                           question_info: Dict[str, Any],\n",
        "                           answer_fact: Optional[Fact],\n",
        "                           reasoning_trace: List[Tuple[Rule, Dict[str, Any], Fact]],\n",
        "                           is_correct: bool,\n",
        "                           ground_truth_fact: Optional[Fact] = None):\n",
        "\n",
        "        print(f\"\\n--- Adaptation Triggered ---\")\n",
        "        print(f\"  Question: \\\"{question_info.get('question', 'N/A')[:50]}...\\\"\")\n",
        "        print(f\"  Answer Correct: {is_correct}\")\n",
        "        print(f\"  Provided Answer: {answer_fact}\")\n",
        "\n",
        "        relevant_rules = set()\n",
        "        if answer_fact and reasoning_trace:\n",
        "\n",
        "             final_steps = [step for step in reasoning_trace if step[2] == answer_fact]\n",
        "             if final_steps:\n",
        "                  relevant_rules.add(final_steps[0][0])\n",
        "\n",
        "        if is_correct:\n",
        "            if answer_fact and relevant_rules:\n",
        "                print(\"  Action: Strengthening rules involved in correct answer.\")\n",
        "                for rule in relevant_rules:\n",
        "                    delta = config.ADAPTATION_LEARNING_RATE_SYMBOLIC * (1.0 - rule.confidence)\n",
        "                    rule.confidence = min(1.0, rule.confidence + delta)\n",
        "                    print(f\"    - Increased confidence of Rule {rule.id} ({rule.source}) to {rule.confidence:.3f}\")\n",
        "            elif answer_fact:\n",
        "                 print(\"  Info: Correct answer was likely an initial fact or trace is incomplete. No rule confidence updated.\")\n",
        "            else:\n",
        "                 print(\"  Warning: Feedback indicates 'correct' but no answer was provided.\")\n",
        "\n",
        "        else:\n",
        "            if answer_fact:\n",
        "                print(\"  Action: Weakening rules involved in incorrect answer.\")\n",
        "                if relevant_rules:\n",
        "                    for rule in relevant_rules:\n",
        "                        delta = config.ADAPTATION_LEARNING_RATE_SYMBOLIC * rule.confidence\n",
        "                        rule.confidence = max(0.05, rule.confidence - delta)\n",
        "                        print(f\"    - Decreased confidence of Rule {rule.id} ({rule.source}) to {rule.confidence:.3f}\")\n",
        "                else:\n",
        "                     print(\"  Info: Cannot identify specific rule(s) leading to the incorrect answer from trace. No confidence updated.\")\n",
        "\n",
        "            else:\n",
        "                print(\"  Action: Attempting to address missing answer.\")\n",
        "                query = question_info.get('query')\n",
        "                relations = question_info.get('relations', [])\n",
        "                if query:\n",
        "                     query_pred = query[0]\n",
        "                     needs_time = any(p in query_pred for p in ['time', 'when', 'arrive', 'depart', 'end', 'start'])\n",
        "                     needs_duration = any(p in query_pred for p in ['duration', 'long', 'takes', 'travel'])\n",
        "                     has_time = any(isinstance(r[2], datetime) for r in relations)\n",
        "                     has_duration = any(isinstance(r[2], timedelta) for r in relations)\n",
        "                     if needs_time and not has_time:\n",
        "                          print(\"    - Possible Issue: Query requires time, but none reliably extracted.\")\n",
        "                     if needs_duration and not has_duration:\n",
        "                          print(\"    - Possible Issue: Query requires duration, but none reliably extracted.\")\n",
        "                else:\n",
        "                     print(\"    - Possible Issue: Query itself was not identified by neural component.\")\n",
        "\n",
        "                print(\"  Action: Triggering dynamic rule generation.\")\n",
        "\n",
        "                temp_reasoner = SymbolicReasoner()\n",
        "                temp_translator = NeuralToSymbolicTranslator()\n",
        "                temp_translator.translate(question_info, temp_reasoner)\n",
        "                initial_facts = temp_reasoner.get_all_facts()\n",
        "\n",
        "                if hasattr(self, 'rule_generator') and self.rule_generator:\n",
        "                    new_rule = self.rule_generator.generate_rule_from_failure(\n",
        "                        question_info=question_info,\n",
        "                        initial_facts=initial_facts,\n",
        "                        existing_rules=self.symbolic_reasoner.get_all_rules(),\n",
        "                        ground_truth_fact=ground_truth_fact\n",
        "                    )\n",
        "\n",
        "                    if new_rule:\n",
        "                        print(f\"    - Generated new rule: {new_rule}\")\n",
        "                        is_redundant = self.rule_generator._is_rule_redundant(new_rule, self.symbolic_reasoner.get_all_rules())\n",
        "                        if not is_redundant:\n",
        "                             added_rule_obj = self.symbolic_reasoner.add_rule(\n",
        "                                  conditions=new_rule.conditions,\n",
        "                                  conclusion=new_rule.conclusion,\n",
        "                                  confidence=new_rule.confidence,\n",
        "                                  source=new_rule.source\n",
        "                             )\n",
        "                             print(f\"    - Added Rule {added_rule_obj.id} to the reasoner.\")\n",
        "                        else:\n",
        "                             print(f\"    - Generated rule is redundant with existing rules. Not added.\")\n",
        "                    else:\n",
        "                        print(\"    - Rule generation did not produce a new rule for this specific case.\")\n",
        "                        self.rule_generator.store_failure(question_info, initial_facts, ground_truth_fact)\n",
        "                else:\n",
        "                     print(\"   - ERROR: Rule generator not available in AdaptiveLearner.\")"
      ],
      "metadata": {
        "id": "zYlcp4owzDEp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dynamic Rule Generator"
      ],
      "metadata": {
        "id": "SjLHaI0s0QKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DynamicRuleGenerator:\n",
        "    def __init__(self):\n",
        "        self.templates = [\n",
        "            {\n",
        "                \"conditions\": [('event_time', '?e', '?t'), ('duration', '?e', '?d')],\n",
        "                \"conclusion\": ('start_work_time', '?e', 'calculate_departure(?t, ?d)'),\n",
        "                \"required_query\": \"start_work_time\"\n",
        "            },\n",
        "            {\n",
        "                 \"conditions\": [('start_time', '?e', '?t1'), ('end_time', '?e', '?t2')],\n",
        "                 \"conclusion\": ('duration', '?e', 'calculate_duration(?t1, ?t2)'),\n",
        "                 \"required_query\": \"duration\"\n",
        "            },\n",
        "             {\n",
        "                 \"conditions\": [('departure_time', '?e', '?t'), ('travel_time', '?e', '?d')],\n",
        "                 \"conclusion\": ('arrival_time', '?e', 'calculate_end(?t, ?d)'),\n",
        "                 \"required_query\": \"arrival_time\"\n",
        "            },\n",
        "             {\n",
        "                 \"conditions\": [('start_time', '?e', '?t')],\n",
        "                 \"conclusion\": ('event_time', '?e', '?t'),\n",
        "                 \"required_query\": \"event_time\"\n",
        "            },\n",
        "            {\n",
        "                 \"conditions\": [('start_time', '?e', '?t'), ('travel_time', '?e', '?d')],\n",
        "                 \"conclusion\": ('arrival_time', '?e', 'calculate_end(?t, ?d)'),\n",
        "                 \"required_query\": \"arrival_time\"\n",
        "            },\n",
        "        ]\n",
        "        self.failed_cases_store: List[Dict[str, Any]] = []\n",
        "        print(f\"Initialized DynamicRuleGenerator with {len(self.templates)} templates.\")\n",
        "\n",
        "    def store_failure(self, question_info: Dict, initial_facts: Set[Fact], ground_truth: Optional[Fact] = None):\n",
        "         if not isinstance(question_info, dict) or not isinstance(initial_facts, set):\n",
        "              print(\"Warning: Invalid input for store_failure.\")\n",
        "              return\n",
        "\n",
        "         self.failed_cases_store.append({\n",
        "             \"question_info\": question_info,\n",
        "             \"initial_facts\": initial_facts,\n",
        "             \"ground_truth\": ground_truth\n",
        "         })\n",
        "\n",
        "    def _is_rule_redundant(self, new_rule: Rule, existing_rules: List[Rule]) -> bool:\n",
        "        new_rule_cond_preds = set(c[0] for c in new_rule.conditions)\n",
        "        new_rule_conc_pred = new_rule.conclusion[0]\n",
        "\n",
        "        new_rule_conc_calc = None\n",
        "        if isinstance(new_rule.conclusion[2], str) and new_rule.conclusion[2].startswith(\"calculate_\"):\n",
        "             match = re.match(r'(calculate_\\w+)\\(.*\\)', new_rule.conclusion[2])\n",
        "             if match: new_rule_conc_calc = match.group(1)\n",
        "\n",
        "        for rule in existing_rules:\n",
        "            if rule.conclusion[0] == new_rule_conc_pred:\n",
        "                existing_rule_cond_preds = set(c[0] for c in rule.conditions)\n",
        "                if existing_rule_cond_preds == new_rule_cond_preds:\n",
        "                     existing_rule_conc_calc = None\n",
        "                     if isinstance(rule.conclusion[2], str) and rule.conclusion[2].startswith(\"calculate_\"):\n",
        "                          match = re.match(r'(calculate_\\w+)\\(.*\\)', rule.conclusion[2])\n",
        "                          if match: existing_rule_conc_calc = match.group(1)\n",
        "                     if new_rule_conc_calc == existing_rule_conc_calc:\n",
        "                          return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def _apply_templates(self,\n",
        "                         query_predicate: str,\n",
        "                         sample_facts: Set[Fact],\n",
        "                         existing_rules: List[Rule]\n",
        "                        ) -> Optional[Rule]:\n",
        "         available_fact_predicates = {f.predicate for f in sample_facts}\n",
        "\n",
        "         for template in self.templates:\n",
        "            if template[\"required_query\"] == query_predicate:\n",
        "                required_cond_preds = {cond[0] for cond in template[\"conditions\"]}\n",
        "                if required_cond_preds.issubset(available_fact_predicates):\n",
        "                    new_rule = Rule(\n",
        "                        conditions=template[\"conditions\"],\n",
        "                        conclusion=template[\"conclusion\"],\n",
        "                        confidence=max(0.1, config.INITIAL_RULE_CONFIDENCE * 0.8),\n",
        "                        source=\"generated\"\n",
        "                    )\n",
        "                    if not self._is_rule_redundant(new_rule, existing_rules):\n",
        "                         return new_rule\n",
        "                    else:\n",
        "                         pass\n",
        "\n",
        "         return None\n",
        "\n",
        "    def generate_rule_from_failure(self,\n",
        "                                   question_info: Dict,\n",
        "                                   initial_facts: Set[Fact],\n",
        "                                   existing_rules: List[Rule],\n",
        "                                   ground_truth_fact: Optional[Fact] = None\n",
        "                                  ) -> Optional[Rule]:\n",
        "        query = question_info.get(\"query\")\n",
        "        if not query or not isinstance(query, tuple) or len(query) != 3:\n",
        "            print(\"WARN: Rule generation skipped: Invalid or missing query in question_info.\")\n",
        "            return None\n",
        "\n",
        "        query_predicate = query[0]\n",
        "        generated_rule = self._apply_templates(query_predicate, initial_facts, existing_rules)\n",
        "\n",
        "        if generated_rule:\n",
        "             return generated_rule\n",
        "        else:\n",
        "             return None\n",
        "\n",
        "    def generate_rules_from_stored_failures(self, existing_rules: List[Rule]) -> List[Rule]:\n",
        "        newly_generated_rules = []\n",
        "        num_failures = len(self.failed_cases_store)\n",
        "\n",
        "        if num_failures < config.RULE_GEN_MIN_SUPPORT:\n",
        "             return newly_generated_rules\n",
        "\n",
        "        print(f\"INFO: Attempting batch rule generation from {num_failures} stored failures.\")\n",
        "\n",
        "        embeddings = []\n",
        "        valid_indices = []\n",
        "        for i, case in enumerate(self.failed_cases_store):\n",
        "             q_info = case.get(\"question_info\", {})\n",
        "             emb = q_info.get(\"embedding\")\n",
        "\n",
        "             if emb is not None and isinstance(emb, torch.Tensor) and emb.ndim == 2 and emb.shape[0] == 1:\n",
        "                  embeddings.append(emb.numpy().flatten())\n",
        "                  valid_indices.append(i)\n",
        "             else:\n",
        "                  emb_info = f\"type {type(emb)}\" if emb is not None else \"None\"\n",
        "                  emb_shape = f\"shape {emb.shape}\" if isinstance(emb, torch.Tensor) else \"\"\n",
        "                  print(f\"Warning: Skipping failure case {i} due to missing or invalid embedding ({emb_info} {emb_shape}).\")\n",
        "\n",
        "\n",
        "        if len(valid_indices) < config.RULE_GEN_MIN_SUPPORT:\n",
        "             print(\"INFO: Batch rule generation skipped: Not enough valid embeddings found.\")\n",
        "             self.failed_cases_store.clear()\n",
        "             return newly_generated_rules\n",
        "\n",
        "        embeddings_np = np.vstack(embeddings)\n",
        "\n",
        "        try:\n",
        "            clustering = AgglomerativeClustering(\n",
        "                n_clusters=None,\n",
        "                distance_threshold=1.0 - config.RULE_GEN_CLUSTER_THRESHOLD,\n",
        "                metric='cosine',\n",
        "                linkage='average'\n",
        "            )\n",
        "            labels = clustering.fit_predict(embeddings_np)\n",
        "            num_clusters = (max(labels) + 1) if labels.size > 0 and max(labels) > -1 else 0\n",
        "            print(f\"INFO: Clustering resulted in {num_clusters} potential clusters.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error during clustering: {e}. Aborting batch rule generation.\")\n",
        "            self.failed_cases_store.clear()\n",
        "            return newly_generated_rules\n",
        "\n",
        "        generated_rules_in_batch = []\n",
        "        for i in range(num_clusters):\n",
        "            cluster_member_indices = [valid_indices[idx] for idx, label in enumerate(labels) if label == i]\n",
        "\n",
        "            if len(cluster_member_indices) >= config.RULE_GEN_MIN_SUPPORT:\n",
        "                print(f\"\\nINFO: Analyzing Cluster {i} with {len(cluster_member_indices)} members.\")\n",
        "                cluster_cases = [self.failed_cases_store[idx] for idx in cluster_member_indices]\n",
        "\n",
        "\n",
        "                common_query_pred = self._find_common_query_predicate(cluster_cases)\n",
        "\n",
        "                if common_query_pred:\n",
        "                    print(f\"  - Common query predicate in cluster: '{common_query_pred}'\")\n",
        "\n",
        "                    sample_facts = cluster_cases[0]['initial_facts']\n",
        "\n",
        "                    generated_rule = self._apply_templates(\n",
        "                        common_query_pred,\n",
        "                        sample_facts,\n",
        "                        existing_rules + generated_rules_in_batch\n",
        "                    )\n",
        "\n",
        "                    if generated_rule:\n",
        "                         print(f\"  - Generated candidate Rule {generated_rule.id} for cluster {i}.\")\n",
        "                         newly_generated_rules.append(generated_rule)\n",
        "                         generated_rules_in_batch.append(generated_rule)\n",
        "                    else:\n",
        "                         print(f\"  - No suitable template found or rule was redundant for cluster {i}.\")\n",
        "                else:\n",
        "                    print(f\"  - Could not determine a common query predicate for cluster {i}.\")\n",
        "\n",
        "        print(f\"\\nINFO: Finished batch processing. Generated {len(newly_generated_rules)} new rules.\")\n",
        "        self.failed_cases_store.clear()\n",
        "        return newly_generated_rules\n",
        "\n",
        "    def _find_common_query_predicate(self, cases: List[Dict]) -> Optional[str]:\n",
        "        query_preds = []\n",
        "        for case in cases:\n",
        "             q_info = case.get(\"question_info\", {})\n",
        "             query = q_info.get(\"query\")\n",
        "             if query and isinstance(query, tuple) and len(query) == 3 and isinstance(query[0], str):\n",
        "                  query_preds.append(query[0])\n",
        "\n",
        "        if not query_preds:\n",
        "            return None\n",
        "\n",
        "        predicate_counts = Counter(query_preds)\n",
        "        most_common = predicate_counts.most_common(1)\n",
        "        return most_common[0][0] if most_common else None\n",
        "\n",
        "gen_reasoner = SymbolicReasoner()\n",
        "generator = DynamicRuleGenerator()\n",
        "\n",
        "q3 = \"The project deadline is 5 PM. I need 2 hours to review it. When should I start?\"\n",
        "\n",
        "bert_hidden_size = 768\n",
        "neural_out3 = {\n",
        "    \"question\": q3,\n",
        "    \"embedding\": torch.randn(1, bert_hidden_size),\n",
        "    \"relations\": [\n",
        "        ('event_time', 'event1', TimeUtils.parse_time(\"5 PM\")),\n",
        "        ('duration', 'event1', TimeUtils.parse_duration(\"2 hours\"))\n",
        "    ],\n",
        "    \"query\": ('start_work_time', 'event1', '?')\n",
        "}\n",
        "initial_facts3 = {\n",
        "    Fact('event_time', 'event1', TimeUtils.parse_time(\"5 PM\")),\n",
        "    Fact('duration', 'event1', TimeUtils.parse_duration(\"2 hours\"))\n",
        "}\n",
        "ground_truth3 = Fact(predicate='start_work_time', subject='event1', object=TimeUtils.parse_time(\"3:00 PM\"))\n",
        "\n",
        "print(\"--- Attempting Rule Generation from Single Failure ---\")\n",
        "\n",
        "rules_before = gen_reasoner.get_all_rules().copy()\n",
        "print(f\"Rules before generation: {len(rules_before)}\")\n",
        "\n",
        "new_rule = generator.generate_rule_from_failure(\n",
        "    neural_out3,\n",
        "    initial_facts3,\n",
        "    rules_before,\n",
        "    ground_truth3\n",
        ")\n",
        "\n",
        "if new_rule:\n",
        "    print(f\"\\nSuccessfully generated new rule:\\n{new_rule}\")\n",
        "\n",
        "    added_rule = gen_reasoner.add_rule(\n",
        "         conditions=new_rule.conditions,\n",
        "         conclusion=new_rule.conclusion,\n",
        "         confidence=new_rule.confidence,\n",
        "         source=new_rule.source\n",
        "    )\n",
        "    print(f\"Rule {added_rule.id} added to reasoner.\")\n",
        "    print(f\"Rules after generation: {len(gen_reasoner.get_all_rules())}\")\n",
        "    print(\"\\n--- Reasoning again with the new rule ---\")\n",
        "    gen_reasoner.clear_facts()\n",
        "    for f in initial_facts3: gen_reasoner.add_fact(f)\n",
        "    new_facts, trace = gen_reasoner.reason()\n",
        "    print(\"New facts derived:\")\n",
        "    for f in new_facts: print(f\"  {f}\")\n",
        "    results = gen_reasoner.query(neural_out3['query'])\n",
        "    print(f\"Query result: {results[0] if results else 'Not Found'}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nFailed to generate a rule for this case from template.\")\n",
        "\n",
        "    generator.store_failure(neural_out3, initial_facts3, ground_truth3)\n",
        "\n",
        "print(\"\\n--- Attempting Batch Rule Generation ---\")\n",
        "\n",
        "q4 = \"Flight leaves at 10 AM, checkin takes 1 hour. When to start checkin?\"\n",
        "neural_out4 = {\n",
        "    \"question\": q4,\n",
        "    \"embedding\": torch.randn(1, bert_hidden_size) * 0.9,\n",
        "    \"relations\": [('event_time', 'event2', TimeUtils.parse_time(\"10 AM\")), ('duration', 'event2', TimeUtils.parse_duration(\"1 hour\"))],\n",
        "    \"query\": ('start_work_time', 'event2', '?'),\n",
        "}\n",
        "initial_facts4 = { Fact('event_time', 'event2', TimeUtils.parse_time(\"10 AM\")), Fact('duration', 'event2', TimeUtils.parse_duration(\"1 hour\"))}\n",
        "ground_truth4 = Fact(predicate='start_work_time', subject='event2', object=TimeUtils.parse_time(\"9:00 AM\"))\n",
        "\n",
        "if not new_rule:\n",
        "     generator.store_failure(neural_out3, initial_facts3, ground_truth3)\n",
        "generator.store_failure(neural_out4, initial_facts4, ground_truth4)\n",
        "\n",
        "\n",
        "batch_rules = generator.generate_rules_from_stored_failures(gen_reasoner.get_all_rules())\n",
        "\n",
        "if batch_rules:\n",
        "     print(\"\\nGenerated rules from batch processing:\")\n",
        "     for rule in batch_rules:\n",
        "          print(f\" - {rule}\")\n",
        "          if not generator._is_rule_redundant(rule, gen_reasoner.get_all_rules()):\n",
        "              added_rule = gen_reasoner.add_rule(\n",
        "                   conditions=rule.conditions, conclusion=rule.conclusion,\n",
        "                   confidence=rule.confidence, source=rule.source\n",
        "              )\n",
        "              print(f\"   Added Rule {added_rule.id} to reasoner.\")\n",
        "          else:\n",
        "              print(f\"   (Rule {rule.id} already exists or is redundant, not re-adding)\")\n",
        "     print(f\"Rules after batch generation: {len(gen_reasoner.get_all_rules())}\")\n",
        "else:\n",
        "     print(\"\\nNo new rules generated from batch processing.\")\n",
        "\n",
        "\n",
        "print(f\"Stored failures after batch processing: {len(generator.failed_cases_store)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM4lTs7H0Sjj",
        "outputId": "fe80c642-d115-43a9-e2e6-02ad22567544"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 6 core temporal rules.\n",
            "Initialized DynamicRuleGenerator with 5 templates.\n",
            "--- Attempting Rule Generation from Single Failure ---\n",
            "Rules before generation: 6\n",
            "\n",
            "Failed to generate a rule for this case from template.\n",
            "\n",
            "--- Attempting Batch Rule Generation ---\n",
            "INFO: Attempting batch rule generation from 3 stored failures.\n",
            "INFO: Clustering resulted in 2 potential clusters.\n",
            "\n",
            "INFO: Analyzing Cluster 0 with 2 members.\n",
            "  - Common query predicate in cluster: 'start_work_time'\n",
            "  - No suitable template found or rule was redundant for cluster 0.\n",
            "\n",
            "INFO: Finished batch processing. Generated 0 new rules.\n",
            "\n",
            "No new rules generated from batch processing.\n",
            "Stored failures after batch processing: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "Ldw6w2Iz09Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_qa_data(file_path: str) -> List[Dict[str, Any]]:\n",
        "    print(f\"Attempting to load QA data from: {file_path}\")\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Error: Data file not found at {file_path}\")\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error: Could not decode JSON from {file_path}. Error: {e}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file {file_path}: {e}\")\n",
        "        return []\n",
        "\n",
        "    if not isinstance(data, list):\n",
        "        print(f\"Error: Invalid data format in {file_path}. Expected a JSON list.\")\n",
        "        return []\n",
        "\n",
        "    processed_data = []\n",
        "    required_keys = {\"question\", \"answer_predicate\", \"answer_value\"}\n",
        "    for i, item in enumerate(data):\n",
        "        if not isinstance(item, dict):\n",
        "            print(f\"Warning: Skipping item {i} in {file_path}, not a dictionary.\")\n",
        "            continue\n",
        "\n",
        "        essential_keys = {\"question\", \"answer_predicate\", \"answer_value\"}\n",
        "        if not essential_keys.issubset(item.keys()):\n",
        "            missing_keys = essential_keys - item.keys()\n",
        "            print(f\"Warning: Skipping item {i} ('{item.get('question', 'N/A')[:30]}...') due to missing keys: {missing_keys}\")\n",
        "            continue\n",
        "\n",
        "        gt_pred = item['answer_predicate']\n",
        "        gt_val_str = item['answer_value']\n",
        "        parsed_gt_value = None\n",
        "        if isinstance(gt_val_str, str):\n",
        "             if 'time' in gt_pred.lower() or 'when' in gt_pred.lower():\n",
        "                  parsed_gt_value = TimeUtils.parse_time(gt_val_str)\n",
        "             elif 'duration' in gt_pred.lower() or 'long' in gt_pred.lower():\n",
        "                  parsed_gt_value = TimeUtils.parse_duration(gt_val_str)\n",
        "\n",
        "             elif gt_val_str.isdigit():\n",
        "                  parsed_gt_value = int(gt_val_str)\n",
        "\n",
        "\n",
        "        item['parsed_answer_value'] = parsed_gt_value\n",
        "        processed_data.append(item)\n",
        "\n",
        "    print(f\"Successfully loaded and processed {len(processed_data)} QA pairs from {file_path}.\")\n",
        "    return processed_data\n",
        "\n",
        "def create_sample_data_file(file_path: str = config.DATA_PATH):\n",
        "    if os.path.exists(file_path):\n",
        "        return\n",
        "    sample_data = [\n",
        "        {\n",
        "            \"id\": \"q1\",\n",
        "            \"question\": \"If I have a meeting at 3 PM and it takes 30 minutes to get there, when should I leave?\",\n",
        "            \"answer_predicate\": \"departure_time\",\n",
        "            \"answer_value\": \"02:30 PM\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"q2\",\n",
        "            \"question\": \"The workshop starts at 9 AM and runs for 3 hours. What time does it finish?\",\n",
        "            \"answer_predicate\": \"end_time\",\n",
        "            \"answer_value\": \"12:00 PM\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"q3\",\n",
        "            \"question\": \"My flight is at 18:00 and I need 1 hour 15 minutes for travel. What's the latest departure time?\",\n",
        "            \"answer_predicate\": \"departure_time\",\n",
        "            \"answer_value\": \"04:45 PM\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"q4\",\n",
        "            \"question\": \"The project deadline is 5 PM. I need 2 hours to review it. When should I start?\",\n",
        "            \"answer_predicate\": \"start_work_time\",\n",
        "            \"answer_value\": \"03:00 PM\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"q5\",\n",
        "            \"question\": \"How long did the meeting last if it started at 2pm and ended at 4:30 PM?\",\n",
        "            \"answer_predicate\": \"duration\",\n",
        "            \"answer_value\": \"2 hours and 30 minutes\"\n",
        "        },\n",
        "         {\n",
        "            \"id\": \"q6\",\n",
        "            \"question\": \"My train leaves at 10:00 AM. The journey is 1 hr 15 min long. When do I arrive?\",\n",
        "            \"answer_predicate\": \"arrival_time\",\n",
        "            \"answer_value\": \"11:15 AM\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        data_dir = os.path.dirname(file_path)\n",
        "        if data_dir and not os.path.exists(data_dir):\n",
        "            os.makedirs(data_dir)\n",
        "            print(f\"Created data directory: {data_dir}\")\n",
        "\n",
        "        with open(file_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(sample_data, f, indent=2)\n",
        "        print(f\"Created sample data file: {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating sample data file {file_path}: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "create_sample_data_file(config.DATA_PATH)\n",
        "\n",
        "loaded_data = load_qa_data(config.DATA_PATH)\n",
        "\n",
        "if loaded_data:\n",
        "    print(f\"\\nSuccessfully loaded {len(loaded_data)} QA pairs.\")\n",
        "    print(\"\\nFirst item:\")\n",
        "    import pprint\n",
        "    pprint.pprint(loaded_data[0], width=100)\n",
        "    print(\"\\nLast item:\")\n",
        "    pprint.pprint(loaded_data[-1], width=100)\n",
        "\n",
        "    print(\"\\nChecking parsed ground truth values (first few):\")\n",
        "    for i in range(min(3, len(loaded_data))):\n",
        "         item = loaded_data[i]\n",
        "         parsed_val = item.get('parsed_answer_value', 'N/A')\n",
        "         print(f\"  Item {i}: Pred='{item['answer_predicate']}', StrVal='{item['answer_value']}', ParsedVal='{parsed_val}' ({type(parsed_val)})\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nFailed to load data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPTwqbKo08Ql",
        "outputId": "100ade87-c282-4c62-90b8-cfe8b14fc283"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to load QA data from: data/sample_qa.json\n",
            "Successfully loaded and processed 6 QA pairs from data/sample_qa.json.\n",
            "\n",
            "Successfully loaded 6 QA pairs.\n",
            "\n",
            "First item:\n",
            "{'answer_predicate': 'departure_time',\n",
            " 'answer_value': '02:30 PM',\n",
            " 'id': 'q1',\n",
            " 'parsed_answer_value': datetime.datetime(2025, 3, 31, 14, 30),\n",
            " 'question': 'If I have a meeting at 3 PM and it takes 30 minutes to get there, when should I '\n",
            "             'leave?'}\n",
            "\n",
            "Last item:\n",
            "{'answer_predicate': 'arrival_time',\n",
            " 'answer_value': '11:15 AM',\n",
            " 'id': 'q6',\n",
            " 'parsed_answer_value': datetime.datetime(2025, 3, 31, 11, 15),\n",
            " 'question': 'My train leaves at 10:00 AM. The journey is 1 hr 15 min long. When do I arrive?'}\n",
            "\n",
            "Checking parsed ground truth values (first few):\n",
            "  Item 0: Pred='departure_time', StrVal='02:30 PM', ParsedVal='2025-03-31 14:30:00' (<class 'datetime.datetime'>)\n",
            "  Item 1: Pred='end_time', StrVal='12:00 PM', ParsedVal='2025-03-31 12:00:00' (<class 'datetime.datetime'>)\n",
            "  Item 2: Pred='departure_time', StrVal='04:45 PM', ParsedVal='2025-03-31 16:45:00' (<class 'datetime.datetime'>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "hEUhj74F1CEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_answer(predicted_fact: Optional[Fact],\n",
        "                    ground_truth_pred: str,\n",
        "                    ground_truth_val_str: str,\n",
        "                    parsed_ground_truth_val: Any) -> bool:\n",
        "    if predicted_fact is None:\n",
        "        return parsed_ground_truth_val is None\n",
        "\n",
        "    if not isinstance(predicted_fact, Fact):\n",
        "         print(\"Warning: evaluate_answer received non-Fact object as prediction.\")\n",
        "         return False\n",
        "\n",
        "    if predicted_fact.predicate != ground_truth_pred:\n",
        "        return False\n",
        "\n",
        "    pred_val = predicted_fact.object\n",
        "    gt_val = parsed_ground_truth_val\n",
        "\n",
        "    if gt_val is None and ground_truth_val_str is not None:\n",
        "         print(f\"Warning: Ground truth value '{ground_truth_val_str}' could not be parsed. Comparing prediction '{pred_val}' as string.\")\n",
        "         return str(pred_val) == ground_truth_val_str\n",
        "\n",
        "    try:\n",
        "        if isinstance(pred_val, datetime) and isinstance(gt_val, datetime):\n",
        "            return pred_val.strftime(\"%H:%M\") == gt_val.strftime(\"%H:%M\")\n",
        "        elif isinstance(pred_val, timedelta) and isinstance(gt_val, timedelta):\n",
        "            return abs(pred_val.total_seconds() - gt_val.total_seconds()) < 60\n",
        "        elif type(pred_val) == type(gt_val):\n",
        "             return pred_val == gt_val\n",
        "        else:\n",
        "             return str(pred_val) == ground_truth_val_str\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during value comparison: Predicted='{pred_val}' ({type(pred_val)}), \"\n",
        "              f\"GT='{gt_val}' ({type(gt_val)}), GT_Str='{ground_truth_val_str}'. Error: {e}\")\n",
        "        return False\n",
        "\n",
        "def run_evaluation(dataset: List[Dict[str, Any]],\n",
        "                   pipeline_func: Callable[[str], Dict[str, Any]]\n",
        "                  ) -> Dict[str, float]:\n",
        "    correct_count = 0\n",
        "    total_count = len(dataset)\n",
        "    total_processing_time = 0\n",
        "    results_log = []\n",
        "    processed_count = 0\n",
        "\n",
        "    if total_count == 0:\n",
        "        print(\"Evaluation dataset is empty.\")\n",
        "        return {\"accuracy\": 0.0, \"average_time_ms\": 0.0}\n",
        "\n",
        "    print(f\"\\n--- Starting Evaluation on {total_count} Questions ---\")\n",
        "\n",
        "    for i, item in enumerate(dataset):\n",
        "        question = item.get('question')\n",
        "        gt_pred = item.get('answer_predicate')\n",
        "        gt_val_str = item.get('answer_value')\n",
        "        parsed_gt_val = item.get('parsed_answer_value')\n",
        "        item_id = item.get('id', f'item_{i}')\n",
        "\n",
        "        if not all([isinstance(question, str), isinstance(gt_pred, str), gt_val_str is not None]):\n",
        "             print(f\"Warning: Skipping invalid dataset item {item_id}: Missing or invalid required fields.\")\n",
        "             continue\n",
        "\n",
        "        print(f\"\\n--- Evaluating {item_id} ({i+1}/{len(dataset)}) ---\")\n",
        "        print(f\"  Q: {question}\")\n",
        "        gt_repr = f\"{gt_pred}(..., {gt_val_str})\"\n",
        "\n",
        "        start_time = time.time()\n",
        "        is_correct = False\n",
        "        pipeline_failed = False\n",
        "        try:\n",
        "            result = pipeline_func(question)\n",
        "        except Exception as e:\n",
        "             print(f\"  ERROR: Pipeline execution failed for question {item_id}: {e}\")\n",
        "             result = {}\n",
        "             pipeline_failed = True\n",
        "        end_time = time.time()\n",
        "        processing_time = (end_time - start_time) * 1000\n",
        "\n",
        "        if not pipeline_failed:\n",
        "            processed_count += 1\n",
        "            total_processing_time += processing_time\n",
        "\n",
        "            predicted_fact = result.get('answer_fact')\n",
        "            adapter = result.get('adapter')\n",
        "            question_info = result.get('question_info')\n",
        "            reasoning_trace = result.get('reasoning_trace', [])\n",
        "            explanation = result.get('explanation', \"No explanation generated.\")\n",
        "\n",
        "            is_correct = evaluate_answer(predicted_fact, gt_pred, gt_val_str, parsed_gt_val)\n",
        "\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "                print(f\"  Result: CORRECT\")\n",
        "                print(f\"  Predicted: {predicted_fact}\")\n",
        "            else:\n",
        "                print(f\"  Result: INCORRECT\")\n",
        "                print(f\"  Predicted: {predicted_fact}\")\n",
        "                print(f\"  Expected:  {gt_repr} (Parsed: {parsed_gt_val})\")\n",
        "\n",
        "            print(f\"  Time: {processing_time:.2f} ms\")\n",
        "\n",
        "            if adapter and question_info:\n",
        "                 ground_truth_fact_obj = None\n",
        "                 if gt_pred and parsed_gt_val is not None:\n",
        "                      subject = 'event_gt'\n",
        "                      if query := question_info.get('query'):\n",
        "                           if isinstance(query, tuple) and len(query) > 1 and isinstance(query[1], str):\n",
        "                                subject = query[1]\n",
        "\n",
        "                      ground_truth_fact_obj = Fact(predicate=gt_pred, subject=subject, object=parsed_gt_val)\n",
        "\n",
        "                 try:\n",
        "                      adapter.update_on_feedback(\n",
        "                          question_info=question_info,\n",
        "                          answer_fact=predicted_fact,\n",
        "                          reasoning_trace=reasoning_trace,\n",
        "                          is_correct=is_correct,\n",
        "                          ground_truth_fact=ground_truth_fact_obj\n",
        "                      )\n",
        "                 except Exception as e:\n",
        "                      print(f\"  ERROR: Adaptation step failed for question {item_id}: {e}\")\n",
        "            else:\n",
        "                 print(\"  WARN: Adaptation info missing in pipeline result or adapter not found. Skipping update.\")\n",
        "\n",
        "        results_log.append({\n",
        "            \"id\": item_id,\n",
        "            \"question\": question,\n",
        "            \"ground_truth_pred\": gt_pred,\n",
        "            \"ground_truth_val_str\": gt_val_str,\n",
        "            \"predicted_fact\": str(predicted_fact) if not pipeline_failed and predicted_fact else None,\n",
        "            \"is_correct\": is_correct,\n",
        "            \"pipeline_failed\": pipeline_failed,\n",
        "            \"processing_time_ms\": processing_time if not pipeline_failed else None,\n",
        "        })\n",
        "\n",
        "    accuracy = correct_count / processed_count if processed_count > 0 else 0.0\n",
        "    average_time = total_processing_time / processed_count if processed_count > 0 else 0.0\n",
        "    failure_rate = (total_count - processed_count) / total_count if total_count > 0 else 0.0\n",
        "\n",
        "    print(f\"\\n--- Evaluation Summary ---\")\n",
        "    print(f\"Total Questions Attempted: {total_count}\")\n",
        "    print(f\"Successfully Processed: {processed_count}\")\n",
        "    print(f\"Pipeline Failures: {total_count - processed_count}\")\n",
        "    print(f\"Correct Answers (among processed): {correct_count}\")\n",
        "    print(f\"Accuracy (on processed): {accuracy:.4f}\")\n",
        "    print(f\"Failure Rate: {failure_rate:.4f}\")\n",
        "    print(f\"Average Processing Time (on processed): {average_time:.2f} ms\")\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"average_time_ms\": average_time,\n",
        "        \"processed_count\": processed_count,\n",
        "        \"total_questions\": total_count,\n",
        "        \"failure_rate\": failure_rate\n",
        "        }"
      ],
      "metadata": {
        "id": "2OtZ84S71A1c"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Pipeline and Execution"
      ],
      "metadata": {
        "id": "-JMhFSY41LrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuroSymbolicPipeline:\n",
        "    def __init__(self):\n",
        "        print(\"--- Initializing Neuro-Symbolic Pipeline ---\")\n",
        "        start_init = time.time()\n",
        "\n",
        "        try:\n",
        "            self.extractor = BertExtractor(model_name=config.BERT_MODEL_NAME, device=config.DEVICE)\n",
        "            self.reasoner = SymbolicReasoner()\n",
        "            self.translator = NeuralToSymbolicTranslator()\n",
        "            self.evaluator = MetaCognitiveEvaluator()\n",
        "\n",
        "            self.rule_generator = DynamicRuleGenerator()\n",
        "            self.adapter = AdaptiveLearner(self.extractor, self.reasoner, self.rule_generator)\n",
        "        except Exception as e:\n",
        "             print(f\"FATAL ERROR during pipeline initialization: {e}\")\n",
        "\n",
        "             raise RuntimeError(\"Pipeline initialization failed\") from e\n",
        "        end_init = time.time()\n",
        "        print(f\"--- Pipeline Initialization Complete ({end_init - start_init:.2f}s) ---\")\n",
        "\n",
        "    def process_question(self, question: str) -> Dict[str, Any]:\n",
        "\n",
        "        result_dict = {\n",
        "            \"question\": question, \"question_info\": None, \"initial_facts\": set(),\n",
        "            \"derived_facts\": set(), \"all_facts\": set(), \"reasoning_trace\": [],\n",
        "            \"answer_fact\": None, \"plausibility\": None, \"explanation\": \"Processing failed early.\",\n",
        "            \"adapter\": self.adapter\n",
        "        }\n",
        "\n",
        "        try:\n",
        "\n",
        "            neural_output = self.extractor.extract_entities_relations(question)\n",
        "            result_dict[\"question_info\"] = neural_output\n",
        "            query_pattern = neural_output.get('query')\n",
        "\n",
        "\n",
        "            self.reasoner.clear_facts()\n",
        "            num_translated = self.translator.translate(neural_output, self.reasoner)\n",
        "            initial_facts = self.reasoner.get_all_facts().copy()\n",
        "            result_dict[\"initial_facts\"] = initial_facts\n",
        "\n",
        "            derived_facts, reasoning_trace = self.reasoner.reason()\n",
        "            all_facts = self.reasoner.get_all_facts()\n",
        "            result_dict[\"derived_facts\"] = derived_facts\n",
        "            result_dict[\"reasoning_trace\"] = reasoning_trace\n",
        "            result_dict[\"all_facts\"] = all_facts\n",
        "\n",
        "            if query_pattern:\n",
        "                results = self.reasoner.query(query_pattern)\n",
        "                if results:\n",
        "\n",
        "                    answer_fact = results[0]\n",
        "\n",
        "            result_dict[\"answer_fact\"] = answer_fact\n",
        "\n",
        "            plausibility_result = None\n",
        "            if answer_fact:\n",
        "                plausibility_result = self.evaluator.evaluate_plausibility(answer_fact, all_facts)\n",
        "\n",
        "            result_dict[\"plausibility\"] = plausibility_result\n",
        "\n",
        "            explanation = self.evaluator.generate_explanation(\n",
        "                query=query_pattern,\n",
        "                answer_fact=answer_fact,\n",
        "                reasoning_trace=reasoning_trace,\n",
        "                plausibility_result=plausibility_result\n",
        "            )\n",
        "            result_dict[\"explanation\"] = explanation\n",
        "\n",
        "        except Exception as e:\n",
        "             print(f\"ERROR during pipeline processing for question '{question[:50]}...': {e}\")\n",
        "             result_dict[\"explanation\"] = f\"Pipeline processing failed: {e}\"\n",
        "\n",
        "        return result_dict\n",
        "\n",
        "def run_pipeline_evaluation_main(pipeline_instance: NeuroSymbolicPipeline, dataset_path: str):\n",
        "    create_sample_data_file(dataset_path)\n",
        "    dataset = load_qa_data(dataset_path)\n",
        "\n",
        "    if not dataset:\n",
        "        print(\"Evaluation skipped: Failed to load dataset.\")\n",
        "        return None\n",
        "\n",
        "    def pipeline_func_wrapper(question: str) -> Dict[str, Any]:\n",
        "         try:\n",
        "             return pipeline_instance.process_question(question)\n",
        "         except Exception as e:\n",
        "             print(f\"ERROR in pipeline_func_wrapper for question '{question[:50]}...': {e}\")\n",
        "\n",
        "             return {\n",
        "                 \"question\": question, \"answer_fact\": None, \"adapter\": pipeline_instance.adapter,\n",
        "                 \"question_info\": None, \"reasoning_trace\": [], \"initial_facts\": set(),\n",
        "                 \"derived_facts\": set(), \"all_facts\": set(), \"plausibility\": None,\n",
        "                 \"explanation\": f\"Pipeline failed: {e}\"\n",
        "             }\n",
        "\n",
        "    print(\"\\n--- Running Evaluation Loop ---\")\n",
        "    evaluation_metrics = run_evaluation(dataset, pipeline_func_wrapper)\n",
        "    print(f\"\\n--- Final Evaluation Metrics ---\")\n",
        "    pprint.pprint(evaluation_metrics)\n",
        "\n",
        "    print(\"\\n--- Attempting Post-Evaluation Batch Rule Generation ---\")\n",
        "    if hasattr(pipeline_instance, 'rule_generator') and hasattr(pipeline_instance, 'reasoner'):\n",
        "        batch_rules = pipeline_instance.rule_generator.generate_rules_from_stored_failures(\n",
        "            pipeline_instance.reasoner.get_all_rules()\n",
        "        )\n",
        "        if batch_rules:\n",
        "            print(f\"Generated {len(batch_rules)} new rules from batch processing:\")\n",
        "            added_count = 0\n",
        "            for rule in batch_rules:\n",
        "                print(f\" - {rule}\")\n",
        "\n",
        "                if not pipeline_instance.rule_generator._is_rule_redundant(rule, pipeline_instance.reasoner.get_all_rules()):\n",
        "                     added_rule = pipeline_instance.reasoner.add_rule(\n",
        "                          conditions=rule.conditions, conclusion=rule.conclusion,\n",
        "                          confidence=rule.confidence, source=rule.source\n",
        "                     )\n",
        "                     print(f\"   Added Rule {added_rule.id} to reasoner.\")\n",
        "                     added_count += 1\n",
        "                else:\n",
        "                     print(f\"   (Rule {rule.id} already exists or is redundant, not re-adding)\")\n",
        "            print(f\"Added {added_count} unique rules from batch generation.\")\n",
        "        else:\n",
        "            print(\"No new rules generated from batch processing.\")\n",
        "    else:\n",
        "        print(\"WARN: Rule generator or reasoner not found in pipeline instance for batch generation.\")\n",
        "\n",
        "    return evaluation_metrics\n",
        "\n",
        "def main():\n",
        "    print(\"=============================================\")\n",
        "    print(\"=== Neuro-Symbolic Meta-Cognitive System ===\")\n",
        "    print(\"=============================================\")\n",
        "\n",
        "    try:\n",
        "        pipeline = NeuroSymbolicPipeline()\n",
        "    except Exception as e:\n",
        "        print(f\"Could not initialize pipeline: {e}. Exiting.\")\n",
        "        return\n",
        "\n",
        "    run_pipeline_evaluation_main(pipeline, config.DATA_PATH)\n",
        "\n",
        "    print(\"\\n=============================================\")\n",
        "    print(\"=== Processing New Question Post-Adaptation ===\")\n",
        "    print(\"=============================================\")\n",
        "\n",
        "    new_q = \"My train journey starts at 1 PM and takes 90 minutes. What time do I arrive?\"\n",
        "\n",
        "    arrival_rule_exists = any(\n",
        "        r.conclusion[0] == 'arrival_time' and\n",
        "        any(c[0]=='start_time' for c in r.conditions)\n",
        "        for r in pipeline.reasoner.get_all_rules()\n",
        "    )\n",
        "    if not arrival_rule_exists:\n",
        "         print(f\"INFO: No direct start_time -> arrival_time rule found. Processing '{new_q}' might fail or require generation.\")\n",
        "\n",
        "    try:\n",
        "        result = pipeline.process_question(new_q)\n",
        "        print(f\"\\nProcessed New Question: '{new_q}'\")\n",
        "        print(f\"Predicted Answer: {result.get('answer_fact')}\")\n",
        "        print(\"\\n--- Explanation for New Question ---\")\n",
        "        print(result.get('explanation', 'No explanation available.'))\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR processing new question '{new_q}': {e}\")\n",
        "\n",
        "    print(\"\\n--- Final State of Rules ---\")\n",
        "    if hasattr(pipeline, 'reasoner'):\n",
        "        rules = pipeline.reasoner.get_all_rules()\n",
        "        if rules:\n",
        "             rules.sort(key=lambda r: r.id)\n",
        "             for rule in rules:\n",
        "                  print(rule)\n",
        "        else:\n",
        "             print(\"No rules found in the reasoner.\")\n",
        "    else:\n",
        "        print(\"Pipeline or reasoner object not available.\")\n",
        "\n",
        "    print(\"\\n=============================================\")\n",
        "    print(\"=== Execution Finished ===\")\n",
        "    print(\"=============================================\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34OsZ7jj1Nex",
        "outputId": "73ac56d6-9370-48a1-9ec6-205313c3df23"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============================================\n",
            "=== Neuro-Symbolic Meta-Cognitive System ===\n",
            "=============================================\n",
            "--- Initializing Neuro-Symbolic Pipeline ---\n",
            "Loading BERT model: bert-base-uncased...\n",
            "BERT model loaded.\n",
            "Added 6 core temporal rules.\n",
            "Initialized DynamicRuleGenerator with 5 templates.\n",
            "--- Pipeline Initialization Complete (0.88s) ---\n",
            "Attempting to load QA data from: data/sample_qa.json\n",
            "Successfully loaded and processed 6 QA pairs from data/sample_qa.json.\n",
            "\n",
            "--- Running Evaluation Loop ---\n",
            "\n",
            "--- Starting Evaluation on 6 Questions ---\n",
            "\n",
            "--- Evaluating q1 (1/6) ---\n",
            "  Q: If I have a meeting at 3 PM and it takes 30 minutes to get there, when should I leave?\n",
            "  Result: CORRECT\n",
            "  Predicted: departure_time(event1, 02:30 PM)\n",
            "  Time: 16.88 ms\n",
            "\n",
            "--- Adaptation Triggered ---\n",
            "  Question: \"If I have a meeting at 3 PM and it takes 30 minute...\"\n",
            "  Answer Correct: True\n",
            "  Provided Answer: departure_time(event1, 02:30 PM)\n",
            "  ERROR: Adaptation step failed for question q1: unhashable type: 'Rule'\n",
            "\n",
            "--- Evaluating q2 (2/6) ---\n",
            "  Q: The workshop starts at 9 AM and runs for 3 hours. What time does it finish?\n",
            "  Result: CORRECT\n",
            "  Predicted: end_time(event1, 12:00 PM)\n",
            "  Time: 16.39 ms\n",
            "\n",
            "--- Adaptation Triggered ---\n",
            "  Question: \"The workshop starts at 9 AM and runs for 3 hours. ...\"\n",
            "  Answer Correct: True\n",
            "  Provided Answer: end_time(event1, 12:00 PM)\n",
            "  ERROR: Adaptation step failed for question q2: unhashable type: 'Rule'\n",
            "\n",
            "--- Evaluating q3 (3/6) ---\n",
            "  Q: My flight is at 18:00 and I need 1 hour 15 minutes for travel. What's the latest departure time?\n",
            "  Result: CORRECT\n",
            "  Predicted: departure_time(event1, 04:45 PM)\n",
            "  Time: 16.55 ms\n",
            "\n",
            "--- Adaptation Triggered ---\n",
            "  Question: \"My flight is at 18:00 and I need 1 hour 15 minutes...\"\n",
            "  Answer Correct: True\n",
            "  Provided Answer: departure_time(event1, 04:45 PM)\n",
            "  ERROR: Adaptation step failed for question q3: unhashable type: 'Rule'\n",
            "\n",
            "--- Evaluating q4 (4/6) ---\n",
            "  Q: The project deadline is 5 PM. I need 2 hours to review it. When should I start?\n",
            "  Result: CORRECT\n",
            "  Predicted: start_work_time(event1, 03:00 PM)\n",
            "  Time: 16.79 ms\n",
            "\n",
            "--- Adaptation Triggered ---\n",
            "  Question: \"The project deadline is 5 PM. I need 2 hours to re...\"\n",
            "  Answer Correct: True\n",
            "  Provided Answer: start_work_time(event1, 03:00 PM)\n",
            "  ERROR: Adaptation step failed for question q4: unhashable type: 'Rule'\n",
            "\n",
            "--- Evaluating q5 (5/6) ---\n",
            "  Q: How long did the meeting last if it started at 2pm and ended at 4:30 PM?\n",
            "ERROR during pipeline processing for question 'How long did the meeting last if it started at 2pm...': cannot access local variable 'answer_fact' where it is not associated with a value\n",
            "  Result: INCORRECT\n",
            "  Predicted: None\n",
            "  Expected:  duration(..., 2 hours and 30 minutes) (Parsed: 2:30:00)\n",
            "  Time: 16.18 ms\n",
            "\n",
            "--- Adaptation Triggered ---\n",
            "  Question: \"How long did the meeting last if it started at 2pm...\"\n",
            "  Answer Correct: False\n",
            "  Provided Answer: None\n",
            "  Action: Attempting to address missing answer.\n",
            "    - Possible Issue: Query requires duration, but none reliably extracted.\n",
            "  Action: Triggering dynamic rule generation.\n",
            "Added 6 core temporal rules.\n",
            "    - Rule generation did not produce a new rule for this specific case.\n",
            "\n",
            "--- Evaluating q6 (6/6) ---\n",
            "  Q: My train leaves at 10:00 AM. The journey is 1 hr 15 min long. When do I arrive?\n",
            "ERROR during pipeline processing for question 'My train leaves at 10:00 AM. The journey is 1 hr 1...': cannot access local variable 'answer_fact' where it is not associated with a value\n",
            "  Result: INCORRECT\n",
            "  Predicted: None\n",
            "  Expected:  arrival_time(..., 11:15 AM) (Parsed: 2025-03-31 11:15:00)\n",
            "  Time: 16.35 ms\n",
            "\n",
            "--- Adaptation Triggered ---\n",
            "  Question: \"My train leaves at 10:00 AM. The journey is 1 hr 1...\"\n",
            "  Answer Correct: False\n",
            "  Provided Answer: None\n",
            "  Action: Attempting to address missing answer.\n",
            "    - Possible Issue: Query itself was not identified by neural component.\n",
            "  Action: Triggering dynamic rule generation.\n",
            "Added 6 core temporal rules.\n",
            "WARN: Rule generation skipped: Invalid or missing query in question_info.\n",
            "    - Rule generation did not produce a new rule for this specific case.\n",
            "\n",
            "--- Evaluation Summary ---\n",
            "Total Questions Attempted: 6\n",
            "Successfully Processed: 6\n",
            "Pipeline Failures: 0\n",
            "Correct Answers (among processed): 4\n",
            "Accuracy (on processed): 0.6667\n",
            "Failure Rate: 0.0000\n",
            "Average Processing Time (on processed): 16.52 ms\n",
            "\n",
            "--- Final Evaluation Metrics ---\n",
            "{'accuracy': 0.6666666666666666,\n",
            " 'average_time_ms': 16.522924105326336,\n",
            " 'failure_rate': 0.0,\n",
            " 'processed_count': 6,\n",
            " 'total_questions': 6}\n",
            "\n",
            "--- Attempting Post-Evaluation Batch Rule Generation ---\n",
            "INFO: Attempting batch rule generation from 2 stored failures.\n",
            "INFO: Clustering resulted in 1 potential clusters.\n",
            "\n",
            "INFO: Analyzing Cluster 0 with 2 members.\n",
            "  - Common query predicate in cluster: 'duration'\n",
            "  - No suitable template found or rule was redundant for cluster 0.\n",
            "\n",
            "INFO: Finished batch processing. Generated 0 new rules.\n",
            "No new rules generated from batch processing.\n",
            "\n",
            "=============================================\n",
            "=== Processing New Question Post-Adaptation ===\n",
            "=============================================\n",
            "INFO: No direct start_time -> arrival_time rule found. Processing 'My train journey starts at 1 PM and takes 90 minutes. What time do I arrive?' might fail or require generation.\n",
            "ERROR during pipeline processing for question 'My train journey starts at 1 PM and takes 90 minut...': cannot access local variable 'answer_fact' where it is not associated with a value\n",
            "\n",
            "Processed New Question: 'My train journey starts at 1 PM and takes 90 minutes. What time do I arrive?'\n",
            "Predicted Answer: None\n",
            "\n",
            "--- Explanation for New Question ---\n",
            "Pipeline processing failed: cannot access local variable 'answer_fact' where it is not associated with a value\n",
            "\n",
            "--- Final State of Rules ---\n",
            "Rule 20 (1.00, core_temporal): IF event_time(?e, ?t) AND travel_time(?e, ?d) THEN departure_time(?e, calculate_departure(?t, ?d))\n",
            "Rule 21 (1.00, core_temporal): IF start_time(?e, ?t) AND duration(?e, ?d) THEN end_time(?e, calculate_end(?t, ?d))\n",
            "Rule 22 (1.00, core_temporal): IF event_time(?e, ?t) AND duration(?e, ?d) THEN end_time(?e, calculate_end(?t, ?d))\n",
            "Rule 23 (1.00, core_temporal): IF start_time(?e, ?t1) AND end_time(?e, ?t2) THEN duration(?e, calculate_duration(?t1, ?t2))\n",
            "Rule 24 (1.00, core_temporal): IF event_time(?e, ?t) AND duration(?e, ?d) THEN start_work_time(?e, calculate_departure(?t, ?d))\n",
            "Rule 25 (1.00, core_temporal): IF departure_time(?e, ?t) AND travel_time(?e, ?d) THEN arrival_time(?e, calculate_end(?t, ?d))\n",
            "\n",
            "=============================================\n",
            "=== Execution Finished ===\n",
            "=============================================\n"
          ]
        }
      ]
    }
  ]
}
